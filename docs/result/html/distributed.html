<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Large Distributed Training &mdash; A4SFramework ai4science documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->

        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=c1325062"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation Guide" href="installation.html" />
    <link rel="prev" title="User-friendly Interface" href="userfriendly.html" />
</head>

<body class="wy-body-for-nav">
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >



          <a href="index.html" class="icon icon-home">
            A4SFramework
          </a>
              <div class="version">
                0.0.5
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="readme.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="userfriendly.html">User-friendly Interface</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Large Distributed Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#zero-optimization">Zero Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-parallelism">Model parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pretrained-layer-spec">Pretrained Layer Spec</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec"><code class="docutils literal notranslate"><span class="pre">PretrainedLayerSpec</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.build"><code class="docutils literal notranslate"><span class="pre">PretrainedLayerSpec.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.create_peft_model"><code class="docutils literal notranslate"><span class="pre">PretrainedLayerSpec.create_peft_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.load_pretrained"><code class="docutils literal notranslate"><span class="pre">PretrainedLayerSpec.load_pretrained()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.partition_load_pretrained"><code class="docutils literal notranslate"><span class="pre">PretrainedLayerSpec.partition_load_pretrained()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.resize_token_embeddings"><code class="docutils literal notranslate"><span class="pre">PretrainedLayerSpec.resize_token_embeddings()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="modelzoo.html">Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="datapipeline.html">Data Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="trainargs.html">Training Args</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">sfm</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">A4SFramework</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Large Distributed Training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/distributed.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">

  <section id="large-distributed-training">
<span id="distributed"></span><h1>Large Distributed Training<a class="headerlink" href="#large-distributed-training" title="Link to this heading"></a></h1>
<section id="zero-optimization">
<h2>Zero Optimization<a class="headerlink" href="#zero-optimization" title="Link to this heading"></a></h2>
<p><a class="reference external" href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/">Zero Optimization/FSDP</a> is a novel optimization technique that allows us to train models with more than 1 billion parameters on a single GPU.</p>
<p>To use zero optimization in A4SFramework, just need to add strategy flag in the training script. For example, to use Zero1 strategy, just add <code class="docutils literal notranslate"><span class="pre">--strategy</span> <span class="pre">Zero1</span></code> in the training script.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">use_env</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">strategy</span> <span class="n">Zero1</span>
</pre></div>
</div>
</section>
<section id="model-parallelism">
<h2>Model parallelism<a class="headerlink" href="#model-parallelism" title="Link to this heading"></a></h2>
<p>A4SFramework leverage <a class="reference external" href="https://github.com/NVIDIA/Megatron-LM">Megatron</a> to support model parallelism. To use model parallelism in A4SFramework, firstly strategy flag is needed in the training script. For example, to use model parallelism with 2 pipeline parallelism and 2 tensor parallelism, just add <code class="docutils literal notranslate"><span class="pre">--strategy</span> <span class="pre">ThreeD</span> <span class="pre">--pipeline_model_parallel_size</span> <span class="pre">2</span> <span class="pre">--tensor_model_parallel_size</span> <span class="pre">2</span></code> in the training script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="o">--</span><span class="n">use_env</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">strategy</span> <span class="n">ThreeD</span> <span class="o">--</span><span class="n">pipeline_model_parallel_size</span> <span class="mi">2</span> <span class="o">--</span><span class="n">tensor_model_parallel_size</span> <span class="mi">2</span>
</pre></div>
</div>
<p>Secondly, model needs to be written in a way that is compatible with model parallelism. For example, to use model parallelism with Chemical Generalist (MFM + Llama2), the model is written in <code class="xref py py-mod docutils literal notranslate"><span class="pre">models.generalist.graphormer_llama</span></code>.</p>
</section>
<section id="pretrained-layer-spec">
<h2>Pretrained Layer Spec<a class="headerlink" href="#pretrained-layer-spec" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="sfm.utils.pretrained_layer_spec.PretrainedLayerSpec">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sfm.utils.pretrained_layer_spec.</span></span><span class="sig-name descname"><span class="pre">PretrainedLayerSpec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">typename</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">module_args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">module_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">LayerSpec</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.build" title="Link to this definition"></a></dt>
<dd><p>Build the stored specification.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.create_peft_model">
<span class="sig-name descname"><span class="pre">create_peft_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lora</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.create_peft_model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.load_pretrained">
<span class="sig-name descname"><span class="pre">load_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.load_pretrained" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.partition_load_pretrained">
<span class="sig-name descname"><span class="pre">partition_load_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.partition_load_pretrained" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.resize_token_embeddings">
<span class="sig-name descname"><span class="pre">resize_token_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoints_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#sfm.utils.pretrained_layer_spec.PretrainedLayerSpec.resize_token_embeddings" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<p>The <a class="reference internal" href="api/sfm.utils.html#module-sfm.utils.pretrained_layer_spec" title="sfm.utils.pretrained_layer_spec"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sfm.utils.pretrained_layer_spec</span></code></a>.PretrainedLayerSpec class is a useful tool for loading pretrained checkpoints and initializing the parameters of large models to prevent out-of-memory (OOM) errors on the CPU.</p>
<p>For example, to load a pretrained checkpoint for the Llama2 decoder layer, we can use the following code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sfm.utils.pretrained_layer_spec</span> <span class="kn">import</span> <span class="n">PretrainedLayerSpec</span>
<span class="kn">from</span> <span class="nn">transformers.models.llama.modeling_llama</span> <span class="kn">import</span> <span class="n">LlamaDecoderLayer</span>

<span class="n">pipe_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
    <span class="n">PretrainedLayerSpec</span><span class="p">(</span>
        <span class="n">LlamaDecoderLayerPP</span><span class="p">,</span>
        <span class="n">config</span><span class="p">,</span>
        <span class="n">load_ckpt</span><span class="o">=</span><span class="n">load_ckpt</span><span class="p">,</span>
        <span class="n">pretrained_ckpt_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">llm_model_name_or_path</span><span class="p">,</span> <span class="s2">&quot;model.layers.</span><span class="si">{}</span><span class="s2">.pt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The detailed usage example of :mod:sfm.utils.pretrained_layer_spec.PretrainedLayerSpec can be find in <code class="xref py py-mod docutils literal notranslate"><span class="pre">models.generalist.graphormer_llama</span></code> as well.</p>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading"></a></h2>
<p>Here are some examples for DDP, Zero, and model parallelism.</p>
<p>Pretraining Graphormer with DDP or Zero:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bash</span> <span class="n">scripts</span><span class="o">/</span><span class="n">graphormer</span><span class="o">/</span><span class="n">pretrain_graphormer</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>Finetuning Graphormer with DDP or Zero:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bash</span> <span class="n">scripts</span><span class="o">/</span><span class="n">graphormer</span><span class="o">/</span><span class="n">ft_graphormer</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>Finetuning Llama2 + Graphormer with model parallelism:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bash</span> <span class="n">scripts</span><span class="o">/</span><span class="n">generalist</span><span class="o">/</span><span class="n">ft_graphormer_llama_smiles</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>Finetuning Llama2 + Graphormer with PP + TP + Zero1:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bash</span> <span class="n">scripts</span><span class="o">/</span><span class="n">generalist</span><span class="o">/</span><span class="n">ftmp_graphormer_llama_smiles</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="userfriendly.html" class="btn btn-neutral float-left" title="User-friendly Interface" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="installation.html" class="btn btn-neutral float-right" title="Installation Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, MSR A4S team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

</body>
</html>

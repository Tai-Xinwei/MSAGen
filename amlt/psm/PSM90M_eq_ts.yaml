# Steps to run:
# 1. copy data folder https://itpeus4data.blob.core.windows.net/shuz/data/pcq-pos-custom/ to your Azure storage blob container
# 2. copy script mae_3d.sh in FoundationModelProp/ to your Azure storage blob container
# 3. Specify the Azure storage account and container to use
# 4. Submit the job with this yaml file
description: equi
env_defaults:
  NODES: 1
  GPUS_PER_NODE: 8
  WANDB_API_KEY: "local-065f023e262b3ae11107532ba5463cd2d800d739"

target:
  service: aml
  # name: es-madft-nc96-eastus2
  name: townsend1

environment:
  # image: yaosen/sfm-py39-torch2.2.2-cuda12.1:20240417_a
  image: ai4s-sfm:20240531.170731
  registry: msrmoldyn.azurecr.io
  username: msrmoldyn
storage:
  blob:
    # storage_account_name: sfmdataeastus2 # Storage account
    # container_name: psm # Container name
    # mount_dir: /blob
    storage_account_name: sfmarca100 # Storage account
    container_name: sfm # Container name
    mount_dir: /blob

code:
  local_dir: ../SFM_framework

jobs:
- name: equiv2-psm-3types-lh-e0.1f9.9
  # tags: [Project_Name:Science_Foundation_Model,ProjectID:PRJ-0209-A40,Experiment:SFM_PSM]
  tags: [Project_Name:Science_Foundation_Model,ProjectID:PRJ-0209-A40,Experiment:SFM_PSM]
  sku: ${NODES}xG${GPUS_PER_NODE}-IB
  identity: managed
  mpi: true
  process_count_per_node: 1
    # sla_tier: premium
  command:
  # - export data_path=/blob/data/
  - export data_path=/nfs6/psmdata/

  - mkdir -p /blob/psm-checkpoints/equiv2-psm-3types-lh-e0.1f9.9
  - export wandb_run_name=equiv2-psm-3types-lh-e0.1f9.9
  - export save_dir=/blob/psm-checkpoints/equiv2-psm-3types-lh-e0.1f9.9
  - export loadcheck_path=/blob/psm-checkpoints/equiv2-psm-3types-lh-e0.1f9.9
  - export molecule_energy_loss_ratio=1.0
  - export material_energy_loss_ratio=0.1
  - export material_force_loss_ratio=9.9
  - export pbc_cutoff=20.0
  - export pbc_expanded_num_cell_per_direction=5
  - export pbc_expanded_token_cutoff=256
  - export pbc_multigraph_cutoff=5.0
  - export pbc_use_local_attention=False
  - export num_pred_attn_layer=4

  - export save_batch_interval=2500
  - export train_batch_size=1024
  - export val_batch_size=1024
  - export gradient_accumulation_steps=4
  # - export val_batch_interval=30000

  - export total_num_steps=2000000
  - export warmup_num_steps=12000
  - export max_lr=1.5e-4
  - export diffusion_noise_std=10.0
  - export equivar_vec_init=ZERO_CENTERED_POS
  - export strategy=Zero1
  - export fp16=False
  - export clean_sample_ratio=0.5
  - export diff_init_lattice_size=10.0
  - export diffusion_sampling="ddpm"
  - export num_timesteps=5000
  - export ddpm_beta_start=1e-7
  - export ddpm_beta_end=2e-3
  - export ddpm_schedule=sigmoid
  - export equivar_use_linear_bias=True
  - export equivar_use_attention_bias=True
  - export data_path_list="PubChemQC-B3LYP-PM6,matter-sim-15M-force-filtered-merged,AFDB50-plddt70.lmdb,matter-sim-15M-merged"
  - export dataset_name_list="pm6,mattersim,afdb,mattersim"
  - export dataset_split_raito="0.4,0.1,0.4,0.1"
  - export dataset_micro_batch_size="4,2,1,2"
  # - export data_path_list="AFDB50-plddt70.lmdb"
  # - export dataset_name_list="afdb"
  # - export dataset_split_raito="1.0"
  # - export dataset_micro_batch_size="1"
  # - export data_path_list="matter-sim-15M-merged"
  # - export dataset_name_list="mattersim"
  # - export dataset_split_raito="1.0"
  # - export dataset_micro_batch_size="2"
  - export use_unified_batch_sampler=True
  - export rescale_loss_with_std=True

  - export wandb_group=Xinran_psm_dev
  - export wandb_team=ai4s-sfm
  - export wandb_project=psm_dev
  - export wandb_key=local-065f023e262b3ae11107532ba5463cd2d800d739
  - eval "$$(conda shell.bash hook)" && conda activate sfm
  - python setup_cython.py build_ext --inplace
  - pip install nvidia-dali-cuda120
  - export layers=6;export hidden_size=1024;bash scripts/psm/pretrain_psm_equiformerv2.sh
  submit_args:
    container_args:
      shm_size: 1024g

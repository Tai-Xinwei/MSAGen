description: nlm_base

env_defaults:
  NODES: 2
  GPUS: 8
  WANDB_API_KEY: "local-094f941ede8eda7a00c307f50595f054be5382f7"


target:
  service: sing
  name: whitney02
  workspace_name: sfm-ws

environment:
  image: ai4s-sfm/amd:20241022.151209
  registry: msrmoldyn.azurecr.io
  username: msrmoldyn
  setup:
  - eval "$$(conda shell.bash hook)" && conda activate sfm
  - python setup_cython.py build_ext --inplace

storage:
  hai1:
    storage_account_name: sfmdataeastus2 # Storage account
    container_name: nlm # Container name
    mount_dir: /nlm

code:
  local_dir: ../SFM_framework

jobs:
- name: nlm_base1b_300B
  sku: ${NODES}xG${GPUS}-MI300
  tags: [Project_Name:Science_Foundation_Model,ProjectID:PRJ-0209-A40,Experiment:SFMV1_Alignment]
  mpi: true
  process_count_per_node: 1
  command:
  - export WANDB_API_KEY=${WANDB_API_KEY}
  - export HSA_ENABLE_SDMA=0
  - export NCCL_IB_PCI_RELAXED_ORDERING=1
  - export NCCL_NET_GDR_LEVEL=3
  - export WANDB_PROJECT=nlm_base1b_300B
  - export WANDB_TEAM=ai4s-sfm
  - export wandb_group=nlm_base1b_300B
  - export NCCL_DEBUG=INFO
  - eval "$$(conda shell.bash hook)" && conda activate sfm
  - pip install -e . --no-deps
  - python setup_cython.py build_ext --inplace
  - export train_batch_size=512
  - export val_batch_size=512
  - export gradient_accumulation_steps=8
  - export train_data_path=/nlm/peiran/llama3_processed_data/lmdb/v5_valid_split
  - export valid_data_path=/nlm/peiran/llama3_processed_data/lmdb/v5_valid_split
  - export dict_path=/nlm/llama/Meta-Llama-3-8B/original
  - export loadcheck_path=/nlm/llama/Meta-Llama-3-8B/original
  - export save_dir=/nlm/peiran/output/sfm1b_mi300_test/
  - bash scripts/nlm/pretrain_nlm_1b_base_amd.sh
  submit_args:
    env:
      AMLT_DOCKERFILE_TEMPLATE: "none"
      _AZUREML_SINGULARITY_JOB_UAI: /subscriptions/3eaeebff-de6e-4e20-9473-24de9ca067dc/resourceGroups/sfm-rg/providers/Microsoft.ManagedIdentity/userAssignedIdentities/sfm-job-identity

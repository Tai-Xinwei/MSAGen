description: train_sfm_nlmmoe_debug

env_defaults:
  NODES: 4
  GPUS: 8
  WANDB_API_KEY: "local-8b231a9559eded7cef00bd550f7330ad2f3ce696"

target:
    service: aml
    name: sfm-nd96amsra100v4-uksouth

# target:
#   service: aml
#   name: townsend1


# target:
#   service: sing
#   name: baltic02
#   workspace_name: msrresrchws

environment:
  image: yaosen/sfm-py39-torch2.2.2-cuda12.1:20240417_a
  registry: msroctocr.azurecr.io
  username: msroctocr

storage:
  hai1:
    storage_account_name: hai1data # Storage account
    container_name: mfm # Container name
    mount_dir: /hai1
  blob:
    storage_account_name: msralaphilly2
    container_name: ml-la
    mount_dir: /blob

code:
  local_dir: .

jobs:
- name: train_sfm_nlm_moe_debug
  sku: ${NODES}xG${GPUS}
  tags:
    - 'ProjectID: PRJ-0209-A40'
  mpi: true
  process_count_per_node: 1
  command:
  - export WANDB_API_KEY=${WANDB_API_KEY}
  - export WANDB_PROJECT=scigptmoe
  - export WANDB_TEAM=ai4s-sfm
  - export wandb_group=nlm_dev
  - export NCCL_DEBUG=INFO
  - eval "$$(conda shell.bash hook)" && conda activate sfm
  - pip install -e . --no-deps
  - export train_batch_size=256
  - export gradient_accumulation_steps=64
  - export pipeline_model_parallel_size=8
  - bash scripts/nlm/pretrain_sfm_nlm_moe_debug.sh
  submit_args:
    container_args:
      shm_size: 1024g
    env:
      SHARED_MEMORY_PERCENT: 1.0

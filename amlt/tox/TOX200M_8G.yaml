 # Steps to run:
# 1. copy data folder https://itpeus4data.blob.core.windows.net/shuz/data/pcq-pos-custom/ to your Azure storage blob container
# 2. copy script mae_3d.sh in FoundationModelProp/ to your Azure storage blob container
# 3. Specify the Azure storage account and container to use
# 4. Submit the job with this yaml file

description: psm

env_defaults:
<<<<<<< HEAD
  NODES: 2
=======
  NODES: 1
>>>>>>> main
  GPUS: 8
  WANDB_API_KEY: "local-094f941ede8eda7a00c307f50595f054be5382f7"

# target:
#   service: sing
#   name: baltic02
#   workspace_name: msrresrchws

<<<<<<< HEAD
# target:
#     service: aml
#     # name: gcrarca100cl1
#     name: sfm-nd96amsra100v4-uksouth
#     # name: sfm-nc96-westus3

target:
  service: singularity
  name: msrresrchvc
  workspace_name: msrresrchws
=======
target:
    service: aml
    # name: gcrarca100cl1
    name: sfm-nd96amsra100v4-uksouth
    # name: sfm-nc96-westus3
>>>>>>> main

environment:
  image: yaosen/sfm-py39-torch2.2.2-cuda12.1:20240417_a
  registry: msroctocr.azurecr.io
  username: msroctocr


storage:
  blob:
    storage_account_name: hai1data # Storage account
    container_name: pfm # Container name
    mount_dir: /blob

code:
  local_dir: ../SFM_framework

jobs:
- name: psm
  tags: [Project_Name:Science_Foundation_Model,ProjectID:PRJ-0209-A40,Experiment:SFMV1_Alignment]
  sku: ${NODES}xG${GPUS}-A100
  sla_tier: premium
  mpi: true
  process_count_per_node: 1
  command:
  - export WANDB_API_KEY=${WANDB_API_KEY}
  - export WANDB_PROJECT=psmpdm_dev
  - export WANDB_TEAM=ai4s-sfm
  - export wandb_group=pdm_dev
  - mkdir /blob/pfmexp/output
  - mkdir /blob/pfmexp/output/pfmdiff150M_16G_prob1261_m5_bs2048_ddpm_pair
  - mkdir /blob/pfmexp/output/pfmdiff150M_16G_prob1261_m5_bs2048_ddpm_pair/checkpoints
  - mkdir ./output
  - export path=run.sh
  - export layers=12
  - export hidden_size=1024
  - export ffn_size=4096
  - export num_head=32
  - export num_3d_bias_kernel=8
  - export atom_loss_coeff=1.0
  - export pos_loss_coeff=1.0
  - export sandwich_ln="true"
  - export dropout=0.0
  - export attn_dropout=0.1
  - export act_dropout=0.1
  - export weight_decay=0.0
  - export droppath_prob=0.0
  - export noise_mode=diff
  - export noise_scale=0.2
  - export mask_ratio=0.5
  - export mode_prob=0.1,0.2,0.6,0.1
  - export d_tilde=1.0
  - export max_lr=2e-4
  - export strategy=Zero1
  - export pipeline_model_parallel_size=0
  - export total_num_steps=2000000
  - export warmup_num_steps=1000
  - export train_batch_size=2048
  - export val_batch_size=2048
  - export max_tokens=16000
  - export max_length=1024
  - export gradient_accumulation_steps=4
  - export log_interval=100
  - export loadcheck_path=/blob/pfmexp/output/pfmdiff150M_16G_prob1261_m5_bs2048_ddpm_pair/checkpoints
  # - export data_path=/blob/data/afdb/48organisms-fullatom.lmdb/
  - export data_path=/blob/data/afdb/AFDB50-plddt70.lmdb/
  - export save_dir=/blob/pfmexp/output/pfmdiff150M_16G_prob1261_m5_bs2048_ddpm_pair/checkpoints
  - eval "$$(conda shell.bash hook)" && conda activate sfm
  - python setup_cython.py build_ext --inplace
  - bash ./scripts/tox/pretrain_tox.sh
  submit_args:
    max_run_duration_seconds: 1209500

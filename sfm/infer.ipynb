{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-24 09:21:29,208] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from accelerate import init_empty_weights\n",
    "from transformers import AutoConfig, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.add_argument import add_argument\n",
    "import argparse\n",
    "import deepspeed\n",
    "import json\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"MFMds\")\n",
    "parser.add_argument(\n",
    "    \"--dataset-name\", type=str, default=\"PM6-Full-3D\", help=\"dataset name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--data_path\", type=str, default=\"./dataset\", help=\"path to dataset\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--loadcheck_path\", type=str, default=\"\", help=\"path to dataset\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-b\",\n",
    "    \"--batch_size\",\n",
    "    default=1024,\n",
    "    type=int,\n",
    "    help=\"mini-batch size (default: 32)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-e\",\n",
    "    \"--epochs\",\n",
    "    default=100,\n",
    "    type=int,\n",
    "    help=\"number of total epochs (default: 50)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--local_rank\",\n",
    "    type=int,\n",
    "    default=-1,\n",
    "    help=\"local rank passed from distributed launcher\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--global_rank\",\n",
    "    type=int,\n",
    "    default=-1,\n",
    "    help=\"global rank passed from distributed launcher\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--backend\", type=str, default=\"nccl\", help=\"distributed backend\"\n",
    ")\n",
    "parser.add_argument(\"--seed\", type=int, default=666666, help=\"PRNG seed\")\n",
    "parser.add_argument(\"--node_rank\", type=int, default=-1)\n",
    "parser.add_argument(\"--rank\", type=int, default=-1)\n",
    "parser.add_argument(\"--num-classes\", type=int, default=1, help=\"number of classes\")\n",
    "parser.add_argument(\n",
    "    \"--encoder_embed_dim\", type=int, default=768, help=\"encoder embedding dimension\"\n",
    ")\n",
    "parser.add_argument(\"--encoder_ffn_embed_dim\", type=int, default=768, help=\"\")\n",
    "parser.add_argument(\n",
    "    \"--llm_hidden_size\", type=int, default=4096, help=\"encoder embedding dimension\"\n",
    ")\n",
    "parser.add_argument(\"--llm_ffn_size\", type=int, default=256, help=\"\")\n",
    "parser.add_argument(\"--encoder_attention_heads\", type=int, default=32, help=\"\")\n",
    "parser.add_argument(\"--encoder_layers\", type=int, default=24, help=\"\")\n",
    "parser.add_argument(\"--max-nodes\", type=int, default=8, help=\"\")\n",
    "parser.add_argument(\"--add-3d\", default=False, action=\"store_true\", help=\"\")\n",
    "parser.add_argument(\"--no-2d\", default=False, action=\"store_true\", help=\"\")\n",
    "parser.add_argument(\"--num-3d-bias-kernel\", type=int, default=128, help=\"\")\n",
    "parser.add_argument(\"--num_pred_attn_layer\", type=int, default=4, help=\"\")\n",
    "parser.add_argument(\"--droppath_prob\", type=float, default=0.0, help=\"\")\n",
    "parser.add_argument(\"--attn_dropout\", type=float, default=0.1, help=\"\")\n",
    "parser.add_argument(\"--act_dropout\", type=float, default=0.1, help=\"\")\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.0, help=\"\")\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=0.0, help=\"\")\n",
    "parser.add_argument(\"--sandwich_ln\", default=True, action=\"store_true\", help=\"\")\n",
    "parser.add_argument(\"--infer\", action=\"store_true\", default=False, help=\"\")\n",
    "parser.add_argument(\"--noise_scale\", type=float, default=0.2, help=\"\")\n",
    "parser.add_argument(\"--mask_ratio\", type=float, default=0.3, help=\"\")\n",
    "parser.add_argument(\"--log-interval\", type=int, default=100, help=\"log per n steps\")\n",
    "parser.add_argument(\n",
    "    \"--pipeline_parallelism\", type=int, default=0, help=\"log per n steps\"\n",
    ")\n",
    "parser.add_argument(\"--steps\", type=int, default=10000000, help=\"log per n steps\")\n",
    "parser.add_argument(\n",
    "    \"--output_path\", type=str, default=\"/blob/output\", help=\"log per n steps\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--d_tilde\", type=float, default=1, help=\"mu transfer multiplier\"\n",
    ")\n",
    "parser.add_argument(\"--max_lr\", type=float, default=1e-3, help=\"max lr\")\n",
    "parser.add_argument(\n",
    "    \"--total_num_steps\",\n",
    "    type=int,\n",
    "    default=1000000,\n",
    ")\n",
    "parser.add_argument(\"--warmup_num_steps\", type=int, default=60000)\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--smiles_dict_path\",\n",
    "    type=str,\n",
    "    default=\"/home/peiran/FMproj/moleculenet_data/data/mol2idx_dict.jsonl\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--llm_model_name_or_path\",\n",
    "    type=str,\n",
    "    default=\"/home/peiran/FMproj/MetaLLM-converted\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--loadmfmcheck_path\",\n",
    "    type=str,\n",
    "    default=\"/home/peiran/FMproj/DiffTM100M/checkpoint7.pt\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--loadllmcheck_path\", type=str, default=\"/home/peiran/FMproj/MetaLLM-converted\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataset_names\", type=str, default=\"hiv,clintox,sider,tox21,bbbp,bace\"\n",
    ")\n",
    "parser.add_argument(\"--dataset_ratios\", type=str, default=\"\")\n",
    "parser.add_argument(\"--dataset_splits\", type=str, default=\"\")\n",
    "parser.add_argument(\"--mol2idx_dict_path\", type=str, default=\"\")\n",
    "parser.add_argument(\"--in_memory\", type=bool, default=False)\n",
    "parser.add_argument(\"--mol_size_path\", type=str, default=\"\")\n",
    "parser.add_argument(\"--pool_mode\", type=str, default=\"qformer\")\n",
    "parser.add_argument(\"--embedding_length\", type=int, default=20)\n",
    "parser.add_argument(\"--btn_adaptor\", type=bool, default=False)\n",
    "parser.add_argument(\"--mfm_lora\", type=bool, default=False)\n",
    "parser.add_argument(\"--model_max_length\", type=int, default=2048)\n",
    "\n",
    "parser = deepspeed.add_config_arguments(parser)\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "global_step = \"global_step6000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "total_size = 0\n",
    "index_map = {\"weight_map\": {}}\n",
    "model_states2 = {}\n",
    "for i in range(37):\n",
    "    ckpt_path = \"/home/peiran/FMproj/output/\" + global_step + f\"/layer_{i:02d}-model_states.pt\"\n",
    "    model_states = torch.load(ckpt_path, map_location='cpu')\n",
    "    # print(ckpt_path)\n",
    "    all_keys = list(model_states.keys())\n",
    "\n",
    "    for key in all_keys:\n",
    "        if key.find('lora') != -1:\n",
    "            continue\n",
    "        if key.find(\"dummy\") != -1:\n",
    "            continue\n",
    "        if key.find(\"partial_learnable_emb\") != -1:\n",
    "            continue\n",
    "        \n",
    "        weight = model_states.pop(key)\n",
    "        key = key.replace(\"base_model.model.\", \"\")\n",
    "\n",
    "        if i == 0:\n",
    "            key = \"graphormer_encoder.\" + key\n",
    "        elif i <= 2:\n",
    "            if key.startswith(\"embed_tokens.weight\"):\n",
    "                key = \"decoder.model.\" + key\n",
    "            else:\n",
    "                key = \"adaptor.\" + key\n",
    "        elif i < 35:\n",
    "            key = \"decoder.model.layers.{}.\".format(i-3) + key\n",
    "        elif i == 35:\n",
    "            key = \"decoder.model.\" + key\n",
    "        elif i == 36:\n",
    "            key = \"decoder.\" + key\n",
    "\n",
    "        # index_map[\"weight_map\"][key] = f\"layer_{i:02d}-model_states.bin\"\n",
    "        model_states2[key] = weight\n",
    "        total_size += weight.nelement() * weight.element_size()\n",
    "        index_map[\"weight_map\"][key] = f\"graphormerllama.bin\"\n",
    "    del model_states\n",
    "\n",
    "    # torch.save(model_states2, \"/home/peiran/FMproj/output/\" + global_step + f\"/layer_{i:02d}-model_states.bin\")\n",
    "torch.save(model_states2, \"/home/peiran/FMproj/output/\" + global_step + f\"/graphormerllama.bin\")\n",
    "del model_states2\n",
    "index_map[\"total_size\"] = total_size\n",
    "\n",
    "with open(\"/home/peiran/FMproj/output/\" +  global_step + \"/graphormerlamma.bin.index.json\", \"w\") as out_file:\n",
    "    json.dump(index_map, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:FoundationModel:Namespace(dataset_name='PM6-Full-3D', data_path='./dataset', loadcheck_path='', batch_size=1024, epochs=100, local_rank=-1, global_rank=-1, backend='nccl', seed=666666, node_rank=-1, rank=-1, num_classes=1, encoder_embed_dim=768, encoder_ffn_embed_dim=768, llm_hidden_size=4096, llm_ffn_size=256, encoder_attention_heads=32, encoder_layers=24, max_nodes=8, add_3d=False, no_2d=False, num_3d_bias_kernel=128, num_pred_attn_layer=4, droppath_prob=0.0, attn_dropout=0.1, act_dropout=0.1, dropout=0.0, weight_decay=0.0, sandwich_ln=True, infer=False, noise_scale=0.2, mask_ratio=0.3, log_interval=100, pipeline_parallelism=0, steps=10000000, output_path='/blob/output', d_tilde=1, max_lr=0.001, total_num_steps=1000000, warmup_num_steps=60000, smiles_dict_path='/home/peiran/FMproj/moleculenet_data/data/mol2idx_dict.jsonl', llm_model_name_or_path='/home/peiran/FMproj/MetaLLM-converted/7B_insft', loadmfmcheck_path='/home/peiran/FMproj/DiffTM100M/checkpoint7.pt', loadllmcheck_path='/home/peiran/FMproj/MetaLLM-converted', dataset_names='hiv,clintox,sider,tox21,bbbp,bace', dataset_ratios='', dataset_splits='', mol2idx_dict_path='', in_memory=False, mol_size_path='', pool_mode='qformer', embedding_length=20, btn_adaptor=False, mfm_lora=False, model_max_length=2048, deepspeed=False, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, ft=True, attention_dropout=0.1, activation_fn='gelu', encoder_normalize_before=True, apply_graphormer_init=True, share_encoder_input_output_embed=False, no_token_positional_embeddings=False, pre_layernorm=False, encoder_learned_pos=False, num_segment=2, sentence_class_num=2, sent_loss=False, apply_bert_init=False, pooler_activation_fn='tanh', atom_loss_coeff=1.0, pos_loss_coeff=1.0, max_positions=512, num_atoms=4608, num_edges=1536, num_in_degree=512, num_out_degree=512, num_spatial=512, num_edge_dis=128, multi_hop_max_dist=5, edge_type='multi_hop')\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "from models.generalist.graphormer_llama import GraphormerLlamaModel\n",
    "\n",
    "args.llm_model_name_or_path = \"/home/peiran/FMproj/MetaLLM-converted/7B_insft\"\n",
    "args.ft = True\n",
    "\n",
    "with init_empty_weights():\n",
    "    model = GraphormerLlamaModel(args, vocab_size=32011)\n",
    "    # model = LlamaForCausalLM.from_pretrained(args.llm_model_name_or_path)\n",
    "\n",
    "names = []\n",
    "for name, parameter in model.named_parameters():\n",
    "    names.append(name)\n",
    "# print(names)\n",
    "\n",
    "json.dump(names, open(\"/home/peiran/FMproj/output/\" + global_step + \"/graphormerlamma.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32011, 4096])\n",
      "torch.Size([32011, 4096])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphormerLlamaModel(\n",
       "  (graphormer_encoder): GraphormerSentenceEncoder(\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (graph_node_feature): GraphNodeFeature(\n",
       "      (atom_encoder): Embedding(4609, 768, padding_idx=0)\n",
       "      (in_degree_encoder): Embedding(512, 768, padding_idx=0)\n",
       "      (out_degree_encoder): Embedding(512, 768, padding_idx=0)\n",
       "      (graph_token): Embedding(1, 768)\n",
       "      (atom_mask_embedding): Embedding(9, 768)\n",
       "    )\n",
       "    (graph_attn_bias): GraphAttnBias(\n",
       "      (edge_encoder): Embedding(1537, 32, padding_idx=0)\n",
       "      (edge_dis_encoder): Embedding(3276800, 1)\n",
       "      (spatial_pos_encoder): Embedding(522, 800, padding_idx=0)\n",
       "      (graph_token_virtual_distance): Embedding(1, 800)\n",
       "    )\n",
       "    (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x GraphormerSentenceEncoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (fc2): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (final_layer_norm_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32011, 4096, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32011, bias=False)\n",
       "  )\n",
       "  (adaptor): HybridEmbeddings(\n",
       "    (mol_rep_layernorm): LlamaRMSNorm()\n",
       "    (mol_adaptor): MLPAdapter(\n",
       "      (gate_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (down_proj): Linear(in_features=768, out_features=4096, bias=False)\n",
       "      (up_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (act_fn): SiLUActivation()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (qformer): Qformer(\n",
       "      (adaptor_qformer_layers): ModuleList(\n",
       "        (0): QformerBlock(\n",
       "          (adaptor_self_attn): EmbedAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (o_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (adaptor_cross_attn): EmbedAttention(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (o_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (adaptor_mlp): MLPAdapter(\n",
       "            (gate_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "            (down_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "            (up_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "            (act_fn): SiLUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate import load_checkpoint_and_dispatch, infer_auto_device_map, dispatch_model, load_checkpoint_in_model\n",
    "\n",
    "device_map = infer_auto_device_map(\n",
    "    model, \n",
    "    no_split_module_classes=[\"LlamaDecoderLayer\", \"GraphormerSentenceEncoderLayer\"],\n",
    "    dtype='float16'\n",
    ")\n",
    "# print(device_map)\n",
    "full_model_device_map = {k: 0 for k, v in device_map.items()}\n",
    "\n",
    "# model = load_checkpoint_in_model(\n",
    "#     model, \"/home/peiran/FMproj/output/\" + global_step, device_map=device_mpa, dtype='float16', offload_state_dict=True \n",
    "# )\n",
    "\n",
    "# model.decoder.tie_weights()\n",
    "\n",
    "model = load_checkpoint_and_dispatch(\n",
    "    model, \n",
    "    \"/home/peiran/FMproj/output/\" + global_step, \n",
    "    device_map=full_model_device_map, \n",
    "    no_split_module_classes=[\"LlamaDecoderLayer\", \"GraphormerSentenceEncoderLayer\"],\n",
    "    offload_state_dict = True, \n",
    "    offload_buffers = True, \n",
    "    dtype='float16'\n",
    ")\n",
    "\n",
    "# full_model_device_map = {f\"model.{k}\": v for k, v in device_map.items()}\n",
    "# full_model_device_map[\"lm_head\"] = 0\n",
    "# dispatch_model(model, device_map=full_model_device_map)\n",
    "\n",
    "print(model.decoder.model.embed_tokens.weight.shape)\n",
    "print(model.decoder.lm_head.weight.shape)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2021.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from data.mol_data.tokenizer import MolTokenizer\n",
    "from utils.move_to_device import move_to_device\n",
    "import torch\n",
    "args.llm_model_name_or_path = \"/home/peiran/FMproj/MetaLLM-converted/7B_insft\"\n",
    "\n",
    "tokenizer = MolTokenizer(args)\n",
    "\n",
    "# batched_smile_data = move_to_device(batched_smile_data, 'cuda:1')\n",
    "# model.decoder.tie_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['### Instruction:\\nGive three reasons whether the molecule can pass the blood-brain barrier?\\n\\n### Input:\\n<mol>', '</mol>\\n\\n### Response:\\n']]\n",
      "['CC[C@@]1(O)C[C@H](O[C@H]2C[C@H](N(C)C)[C@H](O[C@H]3C[C@@H]4O[C@H]5CC(=O)[C@H](C)O[C@H]5O[C@@H]4[C@H](C)O3)[C@H](C)O2)c2c(O)c3c(c(O)c2[C@H]1O[C@H]1C[C@H](N(C)C)[C@H](O)[C@H](C)O1)C(=O)c1cccc(O)c1C3=O']\n",
      "tensor([[    1,   835,  2799,  4080, 29901,    13, 29954,   573,  2211,  9590,\n",
      "          3692,   278, 13206, 29883,  1297,   508,  1209,   278, 10416, 29899,\n",
      "          2634,   262,  2594,  4336, 29973,    13,    13,  2277, 29937, 10567,\n",
      "         29901, 32001,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,\n",
      "            -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,\n",
      "            -1,    -1, 32002,   835, 13291, 29901,    13]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['### Instruction:\\nGive three reasons whether the molecule can pass the blood-brain barrier?\\n\\n### Input:\\n<mol>CC[C@@]1(O)C[C@H](O[C@H]2C[C@H](N(C)C)[C@H](O[C@H]3C[C@@H]4O[C@H]5CC(=O)[C@H](C)O[C@H]5O[C@@H]4[C@H](C)O3)[C@H](C)O2)c2c(O)c3c(c(O)c2[C@H]1O[C@H]1C[C@H](N(C)C)[C@H](O)[C@H](C)O1)C(=O)c1cccc(O)c1C3=O</mol>\\n\\n### Response:\\n']\n",
      "<s> In-vivo, the compound is a substrate of P-gp, an efflux pump. This is in contrast to the reference standard, which does not have any substrate activity. In-vitro, the compound has a high affinity for P-gp.</s>\n"
     ]
    }
   ],
   "source": [
    "# text = [\"#Prompt: The smile of the molecule is <mol> c1ccc(C2CN=C3NCCN32)cc1 </mol>, give its description\"]\n",
    "# text = [\"### Instruction: \\nWhat can you tell me about this molecule?\\n  ###Input: <mol> CCCCCc1cccc([C@@]2(c3ccc(OC(F)F)cc3)N=C(N)N(C)C2=O)c1 </mol> ### Response:\\n\"]\n",
    "# text = [\"### Instruction:\\nWhat can you tell me about this molecule?\\n  ###Input: <mol> c1ccc(C2CN=C3NCCN32)cc1 </mol> ### Response:\\n\"]\n",
    "# text = [\"### Instruction:\\nWhat can you tell me about this molecule?\\n  ###Input: <mol> C1=C(OC(=C1)C(=O)OCCO)C(=O)[O-1] </mol> ### Response:\\n\"]\n",
    "# text = [\"### Instruction:\\nWhat can you tell me about this molecule?\\n  ###Input: <mol> CC1=CC(=NC(=C1)C)C </mol> ### Response:\\n\"]\n",
    "# text = [\"### Instruction:\\nWhat can you tell me about this molecule?\\n\\n###Input:\\n<mol>CCC(CC(C)(C)C(=O)O)C1=CC=CC=C1</mol>\\n\\n### Response:\\n\"]\n",
    "# text = [\"### Instruction:\\nProvide a brief overview of this molecule.\\n\\n###Input:\\n<mol>CC(=O)C</mol>\\n\\n### Response:\\n\"]\n",
    "\n",
    "smile_list = [\"CCCCCc1cccc([C@@]2(c3ccc(OC(F)F)cc3)N=C(N)N(C)C2=O)c1\", \n",
    "              \"c1ccc(C2CN=C3NCCN32)cc1\", \n",
    "              \"C1=C(OC(=C1)C(=O)OCCO)C(=O)[O-1]\", \n",
    "              \"CC1=CC(=NC(=C1)C)C\",\n",
    "              \"CCC(CC(C)(C)C(=O)O)C1=CC=CC=C1\", \n",
    "              \"O=C(COc1ccc(Cl)cc1)OCCNC12CC3CC(CC(C3)C1)C2\",\n",
    "              \"CC(=O)C\",\n",
    "              \"C[C@]1(Cn2ccnn2)[C@H](C(=O)O)N2C(=O)C[C@H]2S1(=O)=O\",\n",
    "              \"CC[C@@]1(O)C[C@H](O[C@H]2C[C@H](N(C)C)[C@H](O[C@H]3C[C@@H]4O[C@H]5CC(=O)[C@H](C)O[C@H]5O[C@@H]4[C@H](C)O3)[C@H](C)O2)c2c(O)c3c(c(O)c2[C@H]1O[C@H]1C[C@H](N(C)C)[C@H](O)[C@H](C)O1)C(=O)c1cccc(O)c1C3=O\",\n",
    "              \"CCCNCC(O)COc1ccccc1C(=O)CCc1ccccc1\",\n",
    "              ]\n",
    "\n",
    "question_list = [\"Is this molecule toxic and why?\",\n",
    "                 \"Is the molecule easily soluble in water and why?\",\n",
    "                 \"Does the molecule has good oral bioavailability and why?\",\n",
    "                 \"Give three reasons whether the molecule can pass the blood-brain barrier?\",\n",
    "                 \"Is the molecule able to penetrate the blood-brain barrier and why?\",\n",
    "                 \"Provide a brief overview of this molecule.\"]\n",
    "\n",
    "smile = smile_list[8]\n",
    "question = question_list[3]\n",
    "text = [\"### Instruction:\\n{}\\n\\n### Input:\\n<mol>{}</mol>\\n\\n### Response:\\n\".format(question, smile)]\n",
    "\n",
    "# text = [\"### Instruction:\\nIs this molecule toxic\\n\\n###Input:\\n<mol>CCCCCc1cccc([C@@]2(c3ccc(OC(F)F)cc3)N=C(N)N(C)C2=O)c1</mol>\\n\\n### Response:\\n\"]\n",
    "# text = [\"### Instruction:\\nIs this molecule able to penetrate blood-brain barrier.\\n\\n###Input:\\n<mol> CCCCCc1cccc([C@@]2(c3ccc(OC(F)F)cc3)N=C(N)N(C)C2=O)c1 </mol>\\n\\n### Response:\\n\"]\n",
    "\n",
    "# text = [\"To fix a broken audio device in my laptop\"]\n",
    "input_ids, batched_smile_data, llm_mask = tokenizer.tokenize(text)\n",
    "print(input_ids)\n",
    "input_ids = input_ids.to('cuda:0')\n",
    "llm_mask = llm_mask.to('cuda:0')\n",
    "res = model.generate(batched_smile_data, input_ids=input_ids, attention_mask=llm_mask, do_sample=True, temperature=0.7, max_new_tokens=256, output_scores=True, return_dict_in_generate=True)\n",
    "# print(res.sequences[0])\n",
    "print(text)\n",
    "res = tokenizer.text_tokenizer.decode(res.sequences[0], skip_special_tokens=False)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['### Instruction:\\nDoes two molecules react with each other and what is the product?\\n\\n### Input:\\n<mol>', '</mol> <mol>', '</mol>\\n\\n### Response:\\n']]\n",
      "['CCO', 'CC(=O)O']\n",
      "tensor([[    1,   835,  2799,  4080, 29901,    13, 25125,  1023, 13206, 21337,\n",
      "          7657,   411,  1269,   916,   322,   825,   338,   278,  3234, 29973,\n",
      "            13,    13,  2277, 29937, 10567, 29901, 32001,    -1,    -1,    -1,\n",
      "            -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,\n",
      "            -1,    -1,    -1,    -1,    -1,    -1,    -1, 32002, 32001,    -2,\n",
      "            -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,\n",
      "            -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2, 32002,\n",
      "           835, 13291, 29901,    13]])\n",
      "['### Instruction:\\nDoes two molecules react with each other and what is the product?\\n\\n### Input:\\n<mol> CCO </mol> <mol> CC(=O)O </mol>\\n\\n### Response:\\n']\n",
      "<s> A: 1,2-dioxetan-3-ol.</s>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fb948998700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# text = [\"###Prompt\\nDoes <mol> O=S(=O)([O-])[O-].[NH4+].[NH4+] </mol> can react with <mol> NC(=O)c1ccccc1 </mol> and what is the product?\\n###Response:\\n\"]\n",
    "# smile1 = \"Cc1ccc(/C=C2\\\\C(=O)C3(C)CCC2C3(C)C)cc1\"\n",
    "# smile2 = \"C[Si](C)(C)n1ccnc1\"\n",
    "smile1 = \"CCO\"\n",
    "smile2 = \"CC(=O)O\"\n",
    "text = [\"### Instruction:\\nDoes two molecules react with each other and what is the product?\\n\\n### Input:\\n<mol> {} </mol> <mol> {} </mol>\\n\\n### Response:\\n\".format(smile1, smile2)]\n",
    "# text = [\"### Instruction:\\nDoes <mol> {} </mol> react with <mol> {} </mol> and what is the product?\\n\\n### Input:\\n<mol> {} </mol> <mol> {} </mol>\\n\\n### Response:\\n\".format(smile1, smile2, smile1, smile2)]\n",
    "\n",
    "# text = [\"###Prompt\\nHow to sythesis <mol> C=CCC#N </mol>\\n###Response:\\n\"]\n",
    "\n",
    "input_ids, batched_smile_data, llm_mask = tokenizer.tokenize(text)\n",
    "# text_list, smile_list, _ = tokenizer.split_text_and_mol(text)\n",
    "\n",
    "# print(text_list, smile_list);exit()\n",
    "print(input_ids)\n",
    "# maksed_input_ids = torch.where(input_ids>0, input_ids, 0)\n",
    "# inputtext = tokenizer.text_tokenizer.decode(maksed_input_ids[0], skip_special_tokens=False)\n",
    "# print(inputtext)\n",
    "\n",
    "input_ids = input_ids.to('cuda:0')\n",
    "llm_mask = llm_mask.to('cuda:0')\n",
    "res = model.generate(batched_smile_data, input_ids=input_ids, attention_mask=llm_mask, do_sample=True, temperature=0.7, max_new_tokens=512, output_scores=True, return_dict_in_generate=True)\n",
    "res = tokenizer.text_tokenizer.decode(res.sequences[0], skip_special_tokens=False)\n",
    "print(text)\n",
    "print(res)\n",
    "\n",
    "# from rdkit import Chem\n",
    "# Chem.MolFromSmiles(smile1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "IPythonConsole.drawOptions.addAtomIndices = True\n",
    "IPythonConsole.molSize = 600,600\n",
    "\n",
    "mol = Chem.MolFromSmiles('C[Si](C)(C)n1ccnc1')\n",
    "mol\n",
    "\n",
    "# def mol_with_atom_index(mol):\n",
    "#     for atom in mol.GetAtoms():\n",
    "#         atom.SetAtomMapNum(atom.GetIdx())\n",
    "#     return mol\n",
    "# mol_with_atom_index(mol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

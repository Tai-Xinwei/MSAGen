{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "from sfm.data.prot_data.dataset import DownstreamLMDBDataset\n",
    "from sfm.data.prot_data.vocalubary import Alphabet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import lmdb\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearnex import patch_sklearn\n",
    "# patch_sklearn()\n",
    "# from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[32m2024-01-05 04:28:59.426\u001b[0m][\u001b[36mINFO\u001b[0m]: Alphabet: {'<cls>': 0, '<pad>': 1, '<eos>': 2, '<unk>': 3, 'L': 4, 'A': 5, 'G': 6, 'V': 7, 'S': 8, 'E': 9, 'R': 10, 'T': 11, 'I': 12, 'D': 13, 'P': 14, 'K': 15, 'Q': 16, 'N': 17, 'F': 18, 'Y': 19, 'M': 20, 'H': 21, 'W': 22, 'C': 23, 'X': 24, 'B': 25, 'U': 26, 'Z': 27, 'O': 28, '.': 29, '-': 30, '<mask>': 31}\n"
     ]
    }
   ],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "class ProteinSequenceFingerprint:\n",
    "    idx_to_tok = {v: k for k, v in Alphabet().tok_to_idx.items()}\n",
    "\n",
    "    def reverse2str(self, tokens):\n",
    "        aaseq = []\n",
    "        for i in tokens:\n",
    "            if i in [self.vocab.unk_idx, self.vocab.padding_idx, self.vocab.cls_idx, self.vocab.mask_idx, self.vocab.eos_idx,]:\n",
    "                continue\n",
    "            aaseq.append(self.idx_to_tok[i])\n",
    "        return \"\".join(aaseq)\n",
    "\n",
    "class ProteinkmerHistogram(ProteinSequenceFingerprint):\n",
    "    def __init__(self, vocab, k):\n",
    "        self.vocab = vocab\n",
    "        self.k = k\n",
    "        # only upper case letters, 25 tokens in total\n",
    "        self.standard_toks = [i for i in vocab.standard_toks if i.isupper()]\n",
    "        self.kmer2idx = {\"\".join(i): idx for idx, i in enumerate(product(self.standard_toks, repeat=k))}\n",
    "\n",
    "    def __call__(self, tokens):\n",
    "        seq = self.reverse2str(tokens)\n",
    "        kmer_count = np.zeros(len(self.kmer2idx))\n",
    "        for i in range(len(seq) - self.k + 1):\n",
    "            kmer = seq[i:i+self.k]\n",
    "            if kmer in self.kmer2idx:\n",
    "                kmer_count[self.kmer2idx[kmer]] += 1\n",
    "        return kmer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[32m2024-01-05 05:30:47.452\u001b[0m][\u001b[36mINFO\u001b[0m]: Load EnzymeCommission train dataset from /mnta/yaosen/data/bfm_benchmark/EnzymeCommission/EnzymeCommission_train.lmdb\n",
      "[\u001b[32m2024-01-05 05:30:47.453\u001b[0m][\u001b[36mINFO\u001b[0m]: Set default args in DownstreamLMDBDataset\n",
      "[\u001b[32m2024-01-05 05:30:47.453\u001b[0m][\u001b[36mINFO\u001b[0m]: Alphabet: {'<cls>': 0, '<pad>': 1, '<eos>': 2, '<unk>': 3, 'L': 4, 'A': 5, 'G': 6, 'V': 7, 'S': 8, 'E': 9, 'R': 10, 'T': 11, 'I': 12, 'D': 13, 'P': 14, 'K': 15, 'Q': 16, 'N': 17, 'F': 18, 'Y': 19, 'M': 20, 'H': 21, 'W': 22, 'C': 23, 'X': 24, 'B': 25, 'U': 26, 'Z': 27, 'O': 28, '.': 29, '-': 30, '<mask>': 31}\n",
      "[\u001b[32m2024-01-05 05:30:47.516\u001b[0m][\u001b[36mWARNING\u001b[0m]: Removed 0 examples from the dataset because they were too long.\n",
      "[\u001b[32m2024-01-05 05:30:47.521\u001b[0m][\u001b[36mINFO\u001b[0m]: Load EnzymeCommission valid dataset from /mnta/yaosen/data/bfm_benchmark/EnzymeCommission/EnzymeCommission_valid.lmdb\n",
      "[\u001b[32m2024-01-05 05:30:47.521\u001b[0m][\u001b[36mINFO\u001b[0m]: Set default args in DownstreamLMDBDataset\n",
      "[\u001b[32m2024-01-05 05:30:47.522\u001b[0m][\u001b[36mINFO\u001b[0m]: Alphabet: {'<cls>': 0, '<pad>': 1, '<eos>': 2, '<unk>': 3, 'L': 4, 'A': 5, 'G': 6, 'V': 7, 'S': 8, 'E': 9, 'R': 10, 'T': 11, 'I': 12, 'D': 13, 'P': 14, 'K': 15, 'Q': 16, 'N': 17, 'F': 18, 'Y': 19, 'M': 20, 'H': 21, 'W': 22, 'C': 23, 'X': 24, 'B': 25, 'U': 26, 'Z': 27, 'O': 28, '.': 29, '-': 30, '<mask>': 31}\n",
      "[\u001b[32m2024-01-05 05:30:47.546\u001b[0m][\u001b[36mWARNING\u001b[0m]: Removed 0 examples from the dataset because they were too long.\n",
      "[\u001b[32m2024-01-05 05:30:47.547\u001b[0m][\u001b[36mINFO\u001b[0m]: Load EnzymeCommission test dataset from /mnta/yaosen/data/bfm_benchmark/EnzymeCommission/EnzymeCommission_test.lmdb\n",
      "[\u001b[32m2024-01-05 05:30:47.547\u001b[0m][\u001b[36mINFO\u001b[0m]: Set default args in DownstreamLMDBDataset\n",
      "[\u001b[32m2024-01-05 05:30:47.548\u001b[0m][\u001b[36mINFO\u001b[0m]: Alphabet: {'<cls>': 0, '<pad>': 1, '<eos>': 2, '<unk>': 3, 'L': 4, 'A': 5, 'G': 6, 'V': 7, 'S': 8, 'E': 9, 'R': 10, 'T': 11, 'I': 12, 'D': 13, 'P': 14, 'K': 15, 'Q': 16, 'N': 17, 'F': 18, 'Y': 19, 'M': 20, 'H': 21, 'W': 22, 'C': 23, 'X': 24, 'B': 25, 'U': 26, 'Z': 27, 'O': 28, '.': 29, '-': 30, '<mask>': 31}\n",
      "[\u001b[32m2024-01-05 05:30:47.567\u001b[0m][\u001b[36mWARNING\u001b[0m]: Removed 0 examples from the dataset because they were too long.\n"
     ]
    }
   ],
   "source": [
    "args = Namespace()\n",
    "args.max_length = 2048\n",
    "args.data_basepath = \"/mnta/yaosen/data/bfm_benchmark\"\n",
    "args.task_name = \"EnzymeCommission\"\n",
    "dataset_dict = DownstreamLMDBDataset.load_dataset(args)\n",
    "trainset = dataset_dict[\"train\"]\n",
    "valset = dataset_dict[\"valid\"]\n",
    "# others are test sets\n",
    "testset_dict = {\n",
    "    k: v for k, v in dataset_dict.items() if k not in [\"train\", \"valid\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15550/15550 [00:14<00:00, 1094.32it/s]\n",
      "100%|██████████| 1729/1729 [00:01<00:00, 1036.57it/s]\n",
      "100%|██████████| 1919/1919 [00:01<00:00, 1143.23it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_seq_target(dset):\n",
    "    seq, Y = [], []\n",
    "    for item in tqdm(dset):\n",
    "        seq.append(item[\"aa\"])\n",
    "        if DownstreamLMDBDataset.TASKINFO[dset.task_name][\"type\"] == \"multi_classification\":\n",
    "            n_class = len(DownstreamLMDBDataset.TASKINFO[dset.task_name][\"classes\"])\n",
    "            y = np.zeros(n_class)\n",
    "            y[item[\"target\"].squeeze()] = 1\n",
    "            Y.append(y)\n",
    "        else:\n",
    "            Y.append(item[\"target\"])\n",
    "    seq, Y = seq, np.array(Y).squeeze()\n",
    "    return seq, Y\n",
    "\n",
    "seq_train, Y_train = load_seq_target(trainset)\n",
    "seq_val, Y_val = load_seq_target(valset)\n",
    "seq_test, Y_test = load_seq_target(testset_dict[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/15550 [00:03<54:14,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-05 05:33:39,904] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 96/15550 [00:06<08:03, 31.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-05 05:33:42,620] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,622] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,627] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,652] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,655] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,677] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,678] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,690] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,704] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,718] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,730] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,753] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-05 05:33:42,781] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 192/15550 [00:06<02:29, 102.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-05 05:33:42,932] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 384/15550 [00:06<00:52, 289.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-05 05:33:43,191] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15550/15550 [00:16<00:00, 948.34it/s] \n",
      "100%|██████████| 1729/1729 [00:01<00:00, 1607.10it/s]\n",
      "100%|██████████| 1919/1919 [00:00<00:00, 2519.17it/s]\n"
     ]
    }
   ],
   "source": [
    "fp = ProteinkmerHistogram(trainset.vocab, 3)\n",
    "X_train = np.array(Parallel(n_jobs=16)(delayed(fp)(i) for i in tqdm(seq_train)))\n",
    "X_val = np.array(Parallel(n_jobs=16)(delayed(fp)(i) for i in tqdm(seq_val)))\n",
    "X_test = np.array(Parallel(n_jobs=16)(delayed(fp)(i) for i in tqdm(seq_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel\n"
     ]
    }
   ],
   "source": [
    "params = {'device': 'cuda', 'seed': 13, 'verbosity': 2, }# 'objective': 'binary:logistic'}\n",
    "if DownstreamLMDBDataset.TASKINFO[args.task_name]['type'] in ['classification', 'binary']:\n",
    "    print(\"classification\")\n",
    "    model = XGBClassifier(**params)\n",
    "elif DownstreamLMDBDataset.TASKINFO[args.task_name]['type'] == 'regression':\n",
    "    print(\"regression\")\n",
    "    model = XGBRegressor(**params)\n",
    "elif DownstreamLMDBDataset.TASKINFO[args.task_name]['type'] == 'multi_classification':\n",
    "    print(\"multilabel\")\n",
    "    # n_class = len(DownstreamLMDBDataset.TASKINFO[trainset.task_name][\"classes\"])\n",
    "    xgb_estimator = XGBClassifier(objective='binary:logistic', **params)\n",
    "    # create MultiOutputClassifier instance with XGBoost model inside\n",
    "    model = MultiOutputClassifier(xgb_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=&#x27;cuda&#x27;,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=&#x27;cuda&#x27;,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device='cuda',\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.6817600413240273, pvalue=2.490754571123554e-72)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.spearmanr(model.predict(X_val), Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.7040444128032343, pvalue=4.981385753838842e-79)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.spearmanr(model.predict(X_test), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, dtype=torch.float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_max(torch.from_numpy(model.predict(X_test)).float(), torch.from_numpy(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5307719672714336"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(X_val)== Y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4579877389109268"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(X_test)== Y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39msquare(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_val) \u001b[38;5;241m-\u001b[39m Y_val)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "np.square(model.predict(X_val) - Y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create sample dataset\n",
    "X, y = make_multilabel_classification(n_samples=3000, n_features=45, n_classes=20, n_labels=1,\n",
    "                                      allow_unlabeled=False, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 45)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def f1_max(pred, target):\n",
    "    \"\"\"\n",
    "    F1 score with the optimal threshold.\n",
    "\n",
    "    This function first enumerates all possible thresholds for deciding positive and negative\n",
    "    samples, and then pick the threshold with the maximal F1 score.\n",
    "\n",
    "    Parameters:\n",
    "        pred (Tensor): predictions of shape :math:`(B, N)`\n",
    "        target (Tensor): binary targets of shape :math:`(B, N)`\n",
    "    \"\"\"\n",
    "    order = pred.argsort(descending=True, dim=1)\n",
    "    target = target.gather(1, order)\n",
    "    precision = target.cumsum(1) / torch.ones_like(target).cumsum(1)\n",
    "    recall = target.cumsum(1) / (target.sum(1, keepdim=True) + 1e-10)\n",
    "    is_start = torch.zeros_like(target).bool()\n",
    "    is_start[:, 0] = 1\n",
    "    is_start = torch.scatter(is_start, 1, order, is_start)\n",
    "\n",
    "    all_order = pred.flatten().argsort(descending=True)\n",
    "    order = (\n",
    "        order\n",
    "        + torch.arange(order.shape[0], device=order.device).unsqueeze(1)\n",
    "        * order.shape[1]\n",
    "    )\n",
    "    order = order.flatten()\n",
    "    inv_order = torch.zeros_like(order)\n",
    "    inv_order[order] = torch.arange(order.shape[0], device=order.device)\n",
    "    is_start = is_start.flatten()[all_order]\n",
    "    all_order = inv_order[all_order]\n",
    "    precision = precision.flatten()\n",
    "    recall = recall.flatten()\n",
    "    all_precision = precision[all_order] - torch.where(\n",
    "        is_start, torch.zeros_like(precision), precision[all_order - 1]\n",
    "    )\n",
    "    all_precision = all_precision.cumsum(0) / is_start.cumsum(0)\n",
    "    all_recall = recall[all_order] - torch.where(\n",
    "        is_start, torch.zeros_like(recall), recall[all_order - 1]\n",
    "    )\n",
    "    all_recall = all_recall.cumsum(0) / pred.shape[0]\n",
    "    all_f1 = 2 * all_precision * all_recall / (all_precision + all_recall + 1e-10)\n",
    "    return all_f1.max()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

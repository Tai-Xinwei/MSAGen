# -*- coding: utf-8 -*-
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict

import hydra
from hydra.core.config_store import ConfigStore
from omegaconf import MISSING, DictConfig, OmegaConf

sys.path.append(str(Path(__file__).resolve().parent.parent))
from sfm.models.psm.psm_config import PSMConfig
from sfm.pipeline.accelerator.dataclasses import DistributedTrainConfig
from sfm.tasks.psm.pretrain_psm import Config


hydra.core.global_hydra.GlobalHydra.instance().clear()


@dataclass
class Config(DistributedTrainConfig, PSMConfig):
    backbone_config: Dict[str, Any] = MISSING
    backbone: str = "graphormer"
    ode_mode: bool = False
    # finetune_module: Optional[str] = None


cs = ConfigStore.instance()
cs.store(name="config_psm_schema", node=Config)

# PSM1B_VT.yaml
# cmd_args = """backbone_config=graphormer backbone=graphormer encoder_attention_heads=32 encoder_layers=18 encoder_ffn_embed_dim=4096 encoder_embed_dim=1024 droppath_prob=0.0 attn_dropout=0.1 act_dropout=0.1 dropout=0.1 weight_decay=0.0 sandwich_ln=True add_3d=True data_path=/blob/AFDBv4-cluster/ data_path_list="AFDB50-plddt70.lmdb" dataset_name_list="afdb" dataset_split_raito="1" save_dir=/blob/psm-checkpoints/so3_integrated_80G1-A100-NvLink seed=12345 ifresume=False mask_ratio=0.0 noise_scale=0.2 num_pred_attn_layer=4 d_tilde=1 strategy=DDP max_lr=2e-4 mode_prob="0.1,0.2,0.7" noise_mode=diff use_2d_atom_features=True use_2d_bond_features=True total_num_steps=2000000 warmup_num_steps=12000 train_batch_size=1024 val_batch_size=1024 max_length=128 gradient_accumulation_steps=4 save_epoch_interval=1 total_num_epochs=1000 save_batch_interval=2500 log_interval=5 loadcheck_path=/home/v-yangtzhang/output/psm equivar_vec_init=ZERO_CENTERED_POS pbc_use_local_attention=True pbc_cutoff=20.0 pbc_expanded_num_cell_per_direction=5 pbc_expanded_token_cutoff=512 pbc_multigraph_cutoff=5.0 diffusion_noise_std=10.0 fp16=False diff_init_lattice_size=10.0 diffusion_sampling=ddpm num_timesteps=5000 ddpm_beta_start=1e-7 ddpm_beta_end=2e-3 ddpm_schedule=sigmoid dataset_micro_batch_size="2" equivar_use_linear_bias=True equivar_use_attention_bias=True use_unified_batch_sampler=True clean_sample_ratio=0.5 sample_in_validation=False sampled_structure_output_path=sample_save_dir psm_validation_mode=False num_sampling_time=1 psm_finetune_mode=False psm_sample_structure_in_finetune=False psm_finetune_reset_head=True rescale_loss_with_std=True only_use_rotary_embedding_for_protein=True use_memory_efficient_attention=False decoder_ffn_dim=1024 wandb=True wandb_group=v-yangtzhang wandb_team=v-yangtzhang wandb_project=psm_dev use_dali_pipeline=False use_value_point=False"""
# PSM1B_V0.yaml
# cmd_args = """backbone_config=graphormer backbone=graphormer encoder_attention_heads=32 encoder_layers=24 encoder_ffn_embed_dim=6144 encoder_embed_dim=1536 droppath_prob=0.0 attn_dropout=0.1 act_dropout=0.1 dropout=0.1 weight_decay=0.0 sandwich_ln=True add_3d=True data_path=/psm/data/ data_path_list="PubChemQC-B3LYP-PM6,matter-sim-15M-force-filtered-merged,AFDB70-plddt70.lmdb,matter-sim-15M-merged,ur50_23_bpe_pack512.lmdb,20240630_PDB_Training_Data,20240630_PDB_Training_Data" dataset_name_list="pm6,mattersim,afdb,mattersim,ur50,pdb,pdbcomplexmultimer" dataset_split_raito="0.2,0.05,0.3,0.15,0.1,0.1,0.1" save_dir=/sfm/sfmexpresults/shiyu/psm-checkpoints/pubchem-pm6-diffusion-molecule-protein-periodic-8xG8-fp32-ddp-unified-sampler-continued-fastpreprocess-20240725-1050 seed=12345 ifresume=True mask_ratio=0.5 noise_scale=0.2 num_pred_attn_layer=4 d_tilde=1 strategy=DDP max_lr=2e-4 mode_prob="0.4,0.5,0.1" noise_mode=diff use_2d_atom_features=True use_2d_bond_features=True total_num_steps=4000000 warmup_num_steps=24000 train_batch_size=1024 val_batch_size=1024 max_length=512 gradient_accumulation_steps=8 save_epoch_interval=1 total_num_epochs=1000 save_batch_interval=2500 log_interval=100 loadcheck_path=/fastdata/peiran/tox/checkpoints/psmV0test/ equivar_vec_init=RELATIVE_POS_VEC_BIAS pbc_use_local_attention=True pbc_cutoff=20.0 pbc_expanded_num_cell_per_direction=5 pbc_expanded_token_cutoff=256 pbc_multigraph_cutoff=5.0 diffusion_noise_std=10.0 fp16=False diff_init_lattice_size=10.0 diffusion_sampling=ddpm num_timesteps=5000 ddpm_beta_start=1e-7 ddpm_beta_end=2e-3 ddpm_schedule=sigmoid dataset_micro_batch_size="12,4,3,4,3,3,3" equivar_use_linear_bias=True equivar_use_attention_bias=True use_unified_batch_sampler=True clean_sample_ratio=0.5 sample_in_validation=False sampled_structure_output_path=sample_save_dir psm_validation_mode=False num_sampling_time=1 psm_finetune_mode=False psm_sample_structure_in_finetune=False psm_finetune_reset_head=True val_batch_log_all_metric=False psm_validate_for_train_set=False rescale_loss_with_std=True only_use_rotary_embedding_for_protein=True use_memory_efficient_attention=False decoder_ffn_dim=6144 wandb=True wandb_group=psm_dev_shiyu_20240719 wandb_team=ai4s-sfm wandb_project=psm_dev_shiyu_20240719 use_dali_pipeline=False wandb_run_name= val_batch_interval=0 psm_matbench_task_name=matbench_dielectric psm_matbench_fold_id=0 psm_finetune_valid_noise_mode=zero diffusion_training_loss=L1 force_loss_type=L1 +energy_per_atom_label_scale=1.0 +molecule_energy_per_atom_std_override=1.0 align_x0_in_diffusion_loss=False num_edges=25600 no_rotary_embedding_for_vector=False node_type_edge_method=NON_EXCHANGABLE force_head_type=GATED_EQUIVARIANT mlm_from_decoder_feature=True num_3d_bias_kernel=128 use_smooth_equviariant_norm=True unified_data_num_workers=4 use_fp32_in_decoder=False material_force_loss_ratio=1.0 material_energy_loss_ratio=1.0 molecule_energy_loss_ratio=1.0"""
# PSM1B_DIT.yaml
# cmd_args = """backbone_config=graphormer backbone=dit encoder_attention_heads=32 encoder_layers=20 num_pred_attn_layer=2 encoder_ffn_embed_dim=6144 encoder_embed_dim=1536 droppath_prob=0.0 attn_dropout=0.1 act_dropout=0.1 dropout=0.0 weight_decay=0.0 sandwich_ln=True data_path=/nfs2/psmdata/ data_path_list="matter-sim-15M-force-filtered-merged,matter-sim-15M-merged,PubChemQC-B3LYP-PM6,AFDB70-plddt70.lmdb,20240101_PDB_Training_Data,20240630_PDB_Training_Data,ESM_ATLAS_reduce.lmdb" dataset_name_list="mattersim,mattersim,pm6,afdb,pdb,pdbcomplexmultimer,esm" dataset_split_raito="0.05,0.15,0.3,0.3,0.01,0.09,0.1" save_dir=/sfm/sfmexpresults/peiran/psmv1_dit_v13_1b/checkpoints seed=6667 mask_ratio=0.3 d_tilde=1.0 strategy=Zero1 max_lr=1e-4 diffusion_mode="epsilon" mode_prob="0.2,0.6,0.2" noise_mode=diff complex_mode_prob="0.4,0.4,0.2" total_num_steps=400000 warmup_num_steps=5000 train_batch_size=1536 val_batch_size=768 max_length=512 gradient_accumulation_steps=8 save_epoch_interval=1 total_num_epochs=1000 save_batch_interval=2500 log_interval=100 equivar_vec_init=RELATIVE_POS_VEC_BIAS pbc_use_local_attention=True pbc_cutoff=20.0 pbc_expanded_num_cell_per_direction=5 pbc_expanded_token_cutoff=256 pbc_multigraph_cutoff=10.0 diffusion_noise_std=10.0 fp16=False psm_validation_mode=False num_edges=25600 num_3d_bias_kernel=32 diff_init_lattice_size=10.0 diffusion_sampling=ddpm num_timesteps=5000 ddpm_beta_start=1e-7 ddpm_beta_end=2e-3 ddpm_schedule=sigmoid dataset_micro_batch_size="8,8,32,8,8,2,8" equivar_use_linear_bias=False equivar_use_attention_bias=False use_unified_batch_sampler=True clean_sample_ratio=0.6 use_2d_atom_features=True use_2d_bond_features=False wandb=True wandb_group=psm_DiT wandb_team=ai4s-sfm wandb_project=psm_VT use_dali_pipeline=False molecule_energy_loss_ratio=1.0 material_energy_loss_ratio=1.0 material_force_loss_ratio=1.0 energy_per_atom_label_scale=1.0 molecule_energy_per_atom_std_override=1.0 preprocess_2d_bond_features_with_cuda=True use_smooth_equviariant_norm=True AutoGradForce=False force_head_type=MLP psm_finetune_mode=False only_use_rotary_embedding_for_protein=True diffusion_training_loss=L1 use_hard_dist_loss=True mm_tensorcore=tf32 compile=False disable_data_aug=False if_total_energy=False decoder_feat4energy=False NoisePredForce=False force_loss_type=L1 rescale_loss_with_std=True align_x0_in_diffusion_loss=False loadcheck_path=/sfm/sfmexpresults/peiran/psmv1_dit_v13_1b/checkpoints ifresume=True"""
# PSM3B_DIT.yaml
cmd_args = """backbone_config=graphormer backbone=seq-dit-geom encoder_attention_heads=32 encoder_layers=16 encoder_ffn_embed_dim=8192 encoder_embed_dim=2048 droppath_prob=0.0 attn_dropout=0.1 act_dropout=0.1 dropout=0.1 weight_decay=0.0 sandwich_ln=True add_3d=True data_path=/psm/data/ data_path_list="MGnify90-selected-plddt70-reduce.lmdb,UniProt90-UniRef50-updated-plddt70-reduce.lmdb,AFDB70-plddt70-reduce-updated.lmdb,20240630_PDB_Training_Data" dataset_name_list="esm,esm,esm,pdbcomplexmultimer" dataset_split_raito="0.2,0.2,0.4,0.2" save_dir=/blob/sfmexpresults/peiran/psmv1_mi300_edm_unify_v22_3b_stage1_5c/checkpoints seed=31682 mask_ratio=0.0 noise_scale=0.2 num_pred_attn_layer=4 d_tilde=1 strategy=Zero1 max_lr=1e-4 mode_prob="0.0,1.0,0.0" noise_mode=diff use_2d_atom_features=True use_2d_bond_features=True total_num_steps=400000 warmup_num_steps=1000 train_batch_size=1024 val_batch_size=1024 max_length=384 gradient_accumulation_steps=4 save_epoch_interval=1 total_num_epochs=1000 save_batch_interval=2500 log_interval=100 loadcheck_path=/psm/sfmexpresults/shiyu/psm-checkpoints/psm-unified-20241228-0909/checkpoint_E1_B80151.pt equivar_vec_init=RELATIVE_POS_VEC_BIAS pbc_use_local_attention=True pbc_cutoff=40.0 pbc_expanded_num_cell_per_direction=5 pbc_expanded_token_cutoff=512 pbc_multigraph_cutoff=7.0 diffusion_noise_std=1.0 fp16=False diff_init_lattice_size=10.0 diffusion_sampling=ddpm num_timesteps=5000 ddpm_beta_start=1e-7 ddpm_beta_end=2e-3 ddpm_schedule=sigmoid dataset_micro_batch_size="16,16,16,16" equivar_use_linear_bias=True equivar_use_attention_bias=True use_unified_batch_sampler=True clean_sample_ratio=0.5 sample_in_validation=False sampled_structure_output_path=sample_save_dir psm_validation_mode=False num_sampling_time=1 psm_finetune_mode=False psm_sample_structure_in_finetune=False psm_finetune_reset_head=False val_batch_log_all_metric=False psm_validate_for_train_set=False rescale_loss_with_std=True only_use_rotary_embedding_for_protein=True use_memory_efficient_attention=False decoder_ffn_dim=8192 wandb=True wandb_group=psm_unified_v23_stage1 wandb_team=peiranjin wandb_project=psm_unified_v23 use_dali_pipeline=False wandb_run_name=unify_3b_training val_batch_interval=0 psm_matbench_task_name=matbench_dielectric psm_matbench_fold_id=0 psm_finetune_valid_noise_mode=diffusion diffusion_training_loss=L2 force_loss_type=L1 energy_per_atom_label_scale=1.0 molecule_energy_per_atom_std_override=1.0 align_x0_in_diffusion_loss=True num_edges=25600 no_rotary_embedding_for_vector=False node_type_edge_method=NON_EXCHANGABLE force_head_type=GATED_EQUIVARIANT mlm_from_decoder_feature=True num_3d_bias_kernel=32 use_smooth_equviariant_norm=True unified_data_num_workers=4 use_fp32_in_decoder=False material_force_loss_ratio=1.0 material_energy_loss_ratio=1.0 molecule_energy_loss_ratio=1.0 val_batch_log_interval=1 complex_mode_prob="1.0,0.0,0.0,0.0" AutoGradForce=True molecule_ref_energy_source=PubChemQC-B3LYP-PM6/wb97xd3/1.0.0/train molecule_outlier_energy_atoms= supervise_force_from_head_when_autograd=True num_timesteps_stepsize=-1 use_fixed_init_lattice_size=False use_adaptive_noise_std_for_periodic=True periodic_diffusion_noise_std_factor=1.0531306506190654 diff_init_lattice_size_factor=2.859496852322873 periodic_lattice_diffusion_noise_std=0.5 share_attention_bias=True mm_tensorcore=fp32 separate_noise_head=True relax_after_sampling_structure=False structure_relax_step_size=1e-3 use_autograd_force_for_relaxation_and_md=True max_residue_num=384 ligand_crop_size=20.0 plddt_threshold=70.0 diffusion_mode=edm decoder_hidden_dim=2048 use_ddpm_for_material=True num_structure_encoder_layer=20 structure_ffn_dim=8192 structure_hidden_dim=2048 use_graphormer_path_edge_feature=False ifresume=True supervise_autograd_stress=True stress_loss_factor=0.1 use_no_pre_cutoff_softmax=True"""

hydra.initialize(version_base=None, config_path="../config_file")
cfg = hydra.compose(
    config_name="config_psm",
    overrides=[v for v in cmd_args.split() if not v.startswith("#")],
)
assert isinstance(cfg, DictConfig)

from sfm.pipeline.accelerator.dataclasses import TrainStrategy

args = OmegaConf.to_object(cfg)
assert isinstance(args, Config)

print("defaults:\n- config_psm_schema\n- _self_\n")
print(OmegaConf.to_yaml(cfg))

model_type: psm
num_classes: 1
encoder_attention_heads: 32
encoder_ffn_embed_dim: 768
encoder_embed_dim: 256
encoder_layers: 8
num_pred_attn_layer: 4
num_3d_bias_kernel: 128
max_length: 512
pbc_expanded_token_cutoff: 512
pbc_expanded_num_cell_per_direction: 5
multi_hop_max_dist: 5
droppath_prob: 0.0
act_dropout: 0.1
attn_dropout: 0.1
dropout: 0.1
sandwich_ln: true
noise_scale: 0.2
mask_ratio: 0.5
d_tilde: 1.0
pbc_cutoff: 40.0
data_path: /home/hul/wangchu/data/
dataset_names: ''
loadcheck_path: '/home/zhangjia/working/sfm_data/checkpoints/checkpoint_E22.pt'
# loadcheck_path: '/home/zhangjia/working/sfm_data/checkpoints/autograd/checkpoint_E157.pt'
add_3d: true
no_2d: false
ft: false
infer: false
use_pbc: false
transformer_m_pretrain: true
mode_prob: 0.1,0.2,0.6,0.1
num_timesteps: 5000
num_timesteps_stepsize: -1
ddpm_beta_start: 0.0001
ddpm_beta_end: 0.02
ddpm_schedule: linear
noise_mode: diff
num_edges: 1536
num_atom_features: 5120
attention_dropout: 0.0
share_encoder_input_output_embed: false
encoder_learned_pos: false
no_token_positional_embeddings: false
num_segments: 2
sentence_class_num: 2
sent_loss: false
apply_bert_init: false
activation_fn: relu
pooler_activation_fn: tanh
encoder_normalize_before: false
atom_loss_coeff: 1.0
pos_loss_coeff: 1.0
y_2d_loss_coeff: 1.0
max_positions: 512
num_atoms: 4608
num_in_degree: 512
num_out_degree: 512
num_spatial: 512
num_edge_dis: 128
edge_type: multi_hop
layerdrop: 0.0
apply_graphormer_init: true
pre_layernorm: false
seq_masking_method: transformerM
add_rope: true
num_residues: 32
max_num_aa: 1024
encoder_pair_embed_dim: 64
decoder_ffn_dim: 1024
task: mae
sample_mode: false
train_data_path: ''
valid_data_path: ''
data_path_list: deshaw-filter/
dataset_name_list: deshaw
dataset_split_raito: '1.0'
dataset_len_ratio_list: ''
dataset_micro_batch_size: '2'
lamb_pde: 0.01
pbc_expanded_distance_cutoff: 20.0
pbc_use_local_attention: true
pbc_multigraph_cutoff: 5.0
diff_init_lattice_size: 4.0
add_unit_cell_virtual_node: false
lattice_size: 4.0
crop_radius: 25.0
diffusion_sampling: ode
diffusion_mode: epsilon
diffusion_noise_std: 1.0
ddim_eta: 0.0
ddim_steps: 50
clean_sample_ratio: 1.0
diffusion_training_loss: L1
diffusion_time_step_encoder_type: POSITIONAL
align_x0_in_diffusion_loss: true
force_loss_type: L1
force_head_type: GATED_EQUIVARIANT
node_type_edge_method: EXCHANGABLE
equivar_vec_init: ZERO_CENTERED_POS
equivar_use_linear_bias: true
equivar_use_attention_bias: true
use_smooth_softmax: false
smooth_factor: 20.0
use_smooth_equviariant_norm: false
no_rotary_embedding_for_vector: false
mlm_from_decoder_feature: true
disable_data_aug: false
use_fp32_in_decoder: false
use_2d_atom_features: false
use_2d_bond_features: false
preprocess_2d_bond_features_with_cuda: true
use_memory_efficient_attention: false
rescale_loss_with_std: false
material_force_loss_ratio: 1.0
material_energy_loss_ratio: 1.0
molecule_energy_loss_ratio: 1.0
energy_per_atom_label_scale: 1.0
molecule_energy_per_atom_std_override: 1.0
decoder_feat4energy: true
AutoGradForce: false
NoisePredForce: false
seq_only: false
freeze_backbone: false
hard_dist_loss_raito: 20.0
use_hard_dist_loss: false
if_total_energy: false
num_force_and_noise_head_layers: 2
psm_validation_mode: false
sample_in_validation: false
num_sampling_time: 1
sampled_structure_output_path: null
psm_finetune_mode: true
psm_sample_structure_in_finetune: false
psm_finetune_reset_head: false
psm_finetune_noise_mode: zero
psm_finetune_valid_noise_mode: zero
only_use_rotary_embedding_for_protein: false
psm_validate_for_train_set: false
psm_matbench_task_name: ''
psm_matbench_fold_id: 0
use_dali_pipeline: false
seed: 12345
total_num_steps: 200000
total_num_epochs: 5000
max_tokens: 2048
train_batch_size: 512
val_batch_size: 512
val_batch_interval: 0
val_batch_log_interval: 1000
val_batch_log_all_metric: false
val_epoch_interval: 1
freeze_param_list: ''
unfreeze_param_list: ''
reset_act_each_step: false
use_unified_batch_sampler: true
activation_checkpoint_interval: 0
checkpointable_layers: null
gradient_clipping: 1.0
strategy: DDP
pp_partition_layer_name: ''
pp_part_list: null
cpu: false
save_dir: ''
save_batch_interval: 10000
save_epoch_interval: 1
log_interval: 20
finetune_from_checkpoint_dir: null
finetune_from_checkpoint_id: null
ifresume: true
load_ckpt: true
max_lr: 0.0002
init_lr: 8.0e-05
min_lr: 8.0e-06
weight_decay: 0.0
beta1: 0.9
beta2: 0.999
eps: 1.0e-08
warmup_num_steps: 1000
warmup_factor: 0.06
warmup_lr: 1.0e-06
warmup_num_epochs: 10
gradient_accumulation_steps: 8
fp16: false
auto_cast: false
grad_scaler_init: 1.0
bf16: false
fp8: false
mm_tensorcore: fp32
compile: false
zero_offload: false
zero_offload_dir: ./
find_unused_parameters: true
dynamic_loader: false
ifstack: false
unified_data_num_workers: 0
wandb: false
wandb_team: faralley
wandb_group: ''
wandb_project: psm_debug_workshop
wandb_run_name: SPICE
early_stopping: false
early_stopping_patience: 10
early_stopping_metric: valid_loss
early_stopping_mode: min
calculate_metrics: false
profiling: false
prof_dir: ./prof
ptensorboard: false
allreduce_log_path: /tmp/stragglers
debug: false
local_rank: -1
world_size: 1
node_rank: 0
rank: 0
pipeline_model_parallel_size: 0
tensor_model_parallel_size: 1
deepspeed_config_path: ''
deepspeed_config: ''
dist_backend: nccl
backbone_config:
  order: 2
  embedding_dim: 256
  bottle_hidden_size: 64
  num_gnn_layers: 8
  radius_embed_dim: 32
  load_pretrain: ''
  max_neighbors: 50
  max_radius: 5
  attn_hidden_channels: 128
  num_heads: 8
  attn_alpha_channels: 32
  attn_value_channels: 16
  ffn_hidden_channels: 512
  max_num_elements: 200
  add_rope: false
  norm_type: layer_norm_sh
  use_gate_act: false
backbone: equiformerv2
train_val_test_split:
- 0.97
- 0.03
- 0.0
shuffle: true
vsc_debug: false
energy_loss_weight: 0.01
force_loss_weight: 0.99
finetune_module: md_energy_force_head
loss_unit: ev

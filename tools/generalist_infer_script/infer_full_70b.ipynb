{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"/home/shiyu/git/SFM_framework/sfm/tasks/ft_graphormer.py\"))))\n",
    "sys.path.append((os.path.dirname(os.path.abspath(\"/home/shiyu/git/SFM_framework/sfm/tasks/ft_graphormer.py\"))))\n",
    "\n",
    "import transformers\n",
    "from accelerate import init_empty_weights\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sfm.models.generalist import GraphormerLlamaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm.utils import add_argument\n",
    "\n",
    "args = add_argument.add_argument()\n",
    "args.num_classes = 1\n",
    "args.encoder_attention_heads = 32\n",
    "args.encoder_layers = 24\n",
    "args.encoder_ffn_embed_dim = 768\n",
    "args.encoder_embed_dim = 768\n",
    "args.droppath_prob = 0.0\n",
    "args.attn_dropout = 0.1\n",
    "args.act_dropout = 0.1\n",
    "args.dropout = 0.0\n",
    "args.weight_decay = 0.0\n",
    "args.sandwich_ln = True\n",
    "args.dataset_names = 'mol-instruction-mol-desc'\n",
    "args.data_path = '/mnt/shiyu/dataset/chemical-copilot'\n",
    "args.output_path = '/mnt/shiyu/models/converted/output'\n",
    "args.pipeline_parallelism = 0\n",
    "args.seed = 666667\n",
    "args.ft = True\n",
    "args.d_tilde = 1\n",
    "args.num_pred_attn_layer = 4\n",
    "args.pool_mode = 'full'\n",
    "args.embedding_length = 1\n",
    "args.llm_model_name_or_path = '/mnt/shiyu/models/converted/ft_100MMFM_70Bllama2_full_mix1/global_step2000'\n",
    "\n",
    "with init_empty_weights():\n",
    "    model = GraphormerLlamaModel(args, 32011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import load_checkpoint_and_dispatch\n",
    "\n",
    "device_map = {\"graphormer_encoder\": 0, \"decoder.model.embed_tokens\": 0, \"adaptor\": 0}\n",
    "for i in range(8):\n",
    "    for j in range(i * 10, i * 10 + 10):\n",
    "        device_map[f'decoder.model.layers.{j}'] = i\n",
    "device_map[\"decoder.model.norm\"] = 7\n",
    "device_map[\"decoder.lm_head\"] = 0\n",
    "\n",
    "model = load_checkpoint_and_dispatch(\n",
    "    model, \"/mnt/shiyu/models/converted/ft_100MMFM_70Bllama2_full_mix1/global_step2000/\", device_map=device_map, no_split_module_classes=[\"LlamaDecoderLayer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "CHEMICAL_TOKENS = [\n",
    "    \"<mol>\",\n",
    "    \"</mol>\",\n",
    "    \"<material>\",\n",
    "    \"</material>\",\n",
    "    \"<protein>\",\n",
    "    \"</protein>\",\n",
    "    \"<dna>\",\n",
    "    \"</dna>\",\n",
    "    \"<rna>\",\n",
    "    \"</rna>\",\n",
    "]\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"/mnt/shiyu/models/converted/llama-2-70b/\",\n",
    "    cache_dir=False,\n",
    "    model_max_length=512,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "special_tokens_dict = dict()\n",
    "if tokenizer.pad_token is None:\n",
    "    special_tokens_dict[\"pad_token\"] = DEFAULT_PAD_TOKEN\n",
    "if tokenizer.eos_token is None:\n",
    "    special_tokens_dict[\"eos_token\"] = DEFAULT_EOS_TOKEN\n",
    "if tokenizer.bos_token is None:\n",
    "    special_tokens_dict[\"bos_token\"] = DEFAULT_BOS_TOKEN\n",
    "if tokenizer.unk_token is None:\n",
    "    special_tokens_dict[\"unk_token\"] = DEFAULT_UNK_TOKEN\n",
    "\n",
    "special_tokens_dict[\"additional_special_tokens\"] = CHEMICAL_TOKENS\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import RemoveHs\n",
    "from sfm.data.mol_data.moltext_dataset import smiles2graph_removeh\n",
    "\n",
    "molecules = ['C1=CC=CC=C1', 'C1=CC(=C(C=C1F)F)N', 'CC(C)OP(=O)(C)OC(C)C', \n",
    "             'N[C@@H](Cc1ccc(O)c(O)c1)C(=O)O',\n",
    "             'C(CC=O)CC=O', 'CC(N)O', 'C(C(Br)Br)(Br)Br', 'CC(C)(C=NOC(=O)NC)SC', 'CCOCC=C', 'CCn1cc(C(=O)O)c(=O)c2cnc(N3CCNCC3)nc21', 'O=C(O)Cc1ccccc1']\n",
    "for i, molecule in enumerate(molecules):\n",
    "        with open(f\"results_70b_ft/mol_{i}.txt\", \"a\") as out_file:\n",
    "                out_file.write(molecule + '\\n')\n",
    "                out_file.write(\"\\n\\n\\n\\n\\n\\n\\n===============================================================================\\n\\n\\n\\n\\n\\n\\n\")\n",
    "                mol = smiles2graph_removeh(molecule)\n",
    "                num_atoms = mol['x'].size()[0]\n",
    "                for question in [\n",
    "                        \"Please give me some details about this molecule.\",\n",
    "                        \"Is this molecule toxic and why?\",\n",
    "                        \"Is the molecule easily soluble in water and why?\",\n",
    "                        \"Does the molecule has good oral bioavailability and why?\",\n",
    "                        \"Can the molecule pass the blood-brain barrier and why?\",\n",
    "                        \"Explain whether the molecule satisfy the Lipinski's rule of five.\"\n",
    "                ]:\n",
    "                        tokenized = tokenizer(\n",
    "                                \"Below is an instruction that describes a question, paired with an input that provides further context. Answer the question as detailed as possible.\\n\\n\"\n",
    "                                f\"### Instruction:\\n{question}\\n\\n### Input:\\n<mol>{''.join(['<unk>' for _ in range(num_atoms)])}<mol>\\n\\n### Response:\\n\",\n",
    "                                return_tensors=\"pt\",\n",
    "                                padding=\"longest\",\n",
    "                                max_length=512,\n",
    "                                truncation=True)\n",
    "                        input_ids = tokenized.input_ids[0]\n",
    "                        input_ids[input_ids == 0] = -1\n",
    "                        input_ids = input_ids.to('cuda')\n",
    "                        res = model.generate_with_smiles(input_ids.unsqueeze(0), do_sample=True, temperature=0.7, max_new_tokens=128, output_scores=True, return_dict_in_generate=True, smiles=[molecule])\n",
    "                        seq = res.sequences[0]\n",
    "                        seq[seq < 0] = 0\n",
    "                        out_file.write(tokenizer.decode(seq, skip_special_tokens=False) + \"\\n\")\n",
    "                        out_file.write(\"\\n\\n\\n\\n\\n\\n\\n===============================================================================\\n\\n\\n\\n\\n\\n\\n\")\n",
    "                        out_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca_mfm_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

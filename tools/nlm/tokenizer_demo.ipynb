{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shufxi/anaconda3/envs/sfm_moe/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-15 07:26:05,094] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from sfm.data.sci_data.NlmTokenizer import NlmTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LlamaTokenizer'. \n",
      "The class this function is called from is 'NlmTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[32m2024-04-15 07:26:06.074\u001b[0m][\u001b[36mINFO\u001b[0m]: Tokenizer has 33982 tokens\n"
     ]
    }
   ],
   "source": [
    "tokenzier = NlmTokenizer.from_pretrained('/hai1/shufxi/Mixtral-8x7B-v0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = tokenzier.tokenize(text)\n",
    "    ids = tokenzier.convert_tokens_to_ids(tokens)\n",
    "    print(\"tokens:\", tokens)\n",
    "    print(\"ids:\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['▁The', '▁quick', '▁brown', '▁f', 'ox', '▁j', 'umps', '▁over', '▁the', '▁lazy', '▁dog']\n",
      "ids: [415, 2936, 9060, 285, 1142, 461, 10575, 754, 272, 17898, 3914]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<mol>', '<m>c', '<m>1', '<m>c', '<m>c', '<m>c', '<m>c', '<m>c', '<m>1', '</mol>']\n",
      "ids: [32001, 32127, 32131, 32127, 32127, 32127, 32127, 32127, 32131, 32002]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<mol>c1ccccc1</mol>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<protein>', '<a>M', '<a>K', '<a>Q', '<a>H', '<a>K', '</protein>']\n",
      "ids: [32007, 33885, 33883, 33889, 33880, 33883, 32008]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<protein>MKQHK</protein>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<dna>', '<d>A', '<d>T', '<d>C', '<d>G', '</dna>']\n",
      "ids: [32009, 33899, 33903, 33901, 33905, 32010]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<dna>ATCG</dna>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<rna>', '<r>A', '<r>U', '<r>C', '<r>G', '</rna>']\n",
      "ids: [32011, 33900, 33908, 33902, 33906, 32012]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<rna>AUCG</rna>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<material>', '<i>Cu', '<i>S', '<i>O', '<i>4', '</material>']\n",
      "ids: [32005, 33556, 33543, 33535, 33935, 32006]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<material>Cu S O 4 </material>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfm_moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-10 07:08:30,370] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from sfm.data.sci_data.NlmTokenizer import NlmTokenizer, NlmLlama3Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LlamaTokenizer'. \n",
      "The class this function is called from is 'NlmTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[32m2024-07-10 07:08:32.338\u001b[0m][\u001b[36mINFO\u001b[0m]: Tokenizer has 33982 tokens\n"
     ]
    }
   ],
   "source": [
    "tokenzier = NlmTokenizer.from_pretrained('/nlm/Mixtral-8x7B-v0.1')\n",
    "\n",
    "# tokenizer = NlmLlama3Tokenizer.from_pretrained('/hai1/Meta-Llama-3-8B/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenzier.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenzier.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = tokenzier.tokenize(text)\n",
    "    ids = tokenzier.convert_tokens_to_ids(tokens)\n",
    "    print(\"tokens:\", tokens)\n",
    "    print(\"ids:\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['▁The', '▁quick', '▁brown', '▁f', 'ox', '▁j', 'umps', '▁over', '▁the', '▁lazy', '▁dog']\n",
      "ids: [415, 2936, 9060, 285, 1142, 461, 10575, 754, 272, 17898, 3914]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<mol>', '<m>c', '<m>1', '<m>c', '<m>c', '<m>c', '<m>c', '<m>c', '<m>1', '</mol>']\n",
      "ids: [32001, 32127, 32131, 32127, 32127, 32127, 32127, 32127, 32131, 32002]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<mol>c1ccccc1</mol>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<protein>', '<a>M', '<a>K', '<a>Q', '<a>H', '<a>K', '</protein>']\n",
      "ids: [32007, 33885, 33883, 33889, 33880, 33883, 32008]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<protein>MKQHK</protein>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<protein>', '<a>M', '<a>K', '<a>Q', '<a>H', '<a>K', '</protein>']\n",
      "ids: [32007, 33885, 33883, 33889, 33880, 33883, 32008]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<protein>MKQHK</protein>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<dna>', '<d>A', '<d>T', '<d>C', '<d>G', '</dna>']\n",
      "ids: [32009, 33899, 33903, 33901, 33905, 32010]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<dna>ATCG</dna>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<rna>', '<r>A', '<r>U', '<r>C', '<r>G', '</rna>']\n",
      "ids: [32011, 33900, 33908, 33902, 33906, 32012]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<rna>AUCG</rna>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['<material>', '<i>Cu', '<i>S', '<i>O', '<i>4', '</material>']\n",
      "ids: [32005, 33556, 33543, 33535, 33935, 32006]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"<material>Cu S O 4 </material>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['▁AA', '<mol>', '<m>C', '<m>C', '</mol>', '▁BB', '<mol>', '<m>C', '<m>C', '</mol>', '▁CC']\n",
      "ids: [24724, 32001, 32128, 32128, 32002, 19942, 32001, 32128, 32128, 32002, 16900]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"AA <mol>CC</mol> BB <mol>CC</mol> CC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['▁', '<0x0A>', '<0x0A>', '<mol>', '<m>C', '<m>C', '</mol>', '▁', '<0x0A>', '<0x0A>', 'Test']\n",
      "ids: [28705, 13, 13, 32001, 32128, 32128, 32002, 28705, 13, 13, 1963]\n"
     ]
    }
   ],
   "source": [
    "tokenize(\"\\n\\n<mol>CC</mol>\\n\\nTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfm_moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

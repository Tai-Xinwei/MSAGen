{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fastdata/peiran/miniconda3/envs/sfm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-08 23:53:41,421] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[\u001b[32m2024-06-08 23:53:41.799\u001b[0m][\u001b[36mINFO\u001b[0m]: apex is installed, using FusedAdam with fp16 optimizer states\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import mmap\n",
    "import re\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import transformers\n",
    "from accelerate import init_empty_weights\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sfm.models.scigpt.scigpt import ScigptModel\n",
    "from sfm.models.scigpt.config import ScigptConfig\n",
    "from sfm.utils import arg_utils\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import multiprocessing as mp\n",
    "from sfm.utils.science_tokens import SCIENCE_TAG_TOKENS, SCIENCE_TOKENS\n",
    "\n",
    "from sfm.logging import logger\n",
    "\n",
    "import struct\n",
    "from multiprocessing import Lock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "def get_args_and_tokenizer(use_llama=False):\n",
    "    parser = ArgumentParser()\n",
    "    cfg_classes = [ScigptConfig]\n",
    "    parser = arg_utils.add_dataclass_to_parser(cfg_classes, parser)\n",
    "    args = parser.parse_args(args=[])\n",
    "    args.load_ckpt = False\n",
    "    args.strategy = \"DDP\"\n",
    "    args.encoder_layers = 33\n",
    "    args.encoder_embed_dim = 1280\n",
    "    args.encoder_ffn_embed_dim = 5120\n",
    "    args.encoder_attention_heads = 20\n",
    "    args.infer = True\n",
    "    args.bf16 = True\n",
    "\n",
    "    llm_path = \"/data/peiran/llama3/Meta-Llama-3-70B/\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(llm_path)\n",
    "    # args.save_dir = \"/home/v-zekunguo/hai1data/nlm/output/llama3_stageB/global_step1600/\"\n",
    "    args.save_dir = llm_path\n",
    "    args.llm_model_name_or_path = llm_path\n",
    "\n",
    "    special_tokens_dict = dict()\n",
    "    if tokenizer.pad_token is None:\n",
    "        special_tokens_dict[\"pad_token\"] = DEFAULT_PAD_TOKEN\n",
    "    if tokenizer.eos_token is None:\n",
    "        special_tokens_dict[\"eos_token\"] = DEFAULT_EOS_TOKEN\n",
    "    if tokenizer.bos_token is None:\n",
    "        special_tokens_dict[\"bos_token\"] = DEFAULT_BOS_TOKEN\n",
    "    if tokenizer.unk_token is None:\n",
    "        special_tokens_dict[\"unk_token\"] = DEFAULT_UNK_TOKEN\n",
    "\n",
    "    # special_tokens_dict[\"additional_special_tokens\"] = SCIENCE_TAG_TOKENS\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    tokenizer.tag_re = re.compile(f'{\"|\".join(SCIENCE_TAG_TOKENS)}')\n",
    "    tokenizer.smiles_re = re.compile(\n",
    "        \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "    )\n",
    "\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\n",
    "            \"pad_token\": \"[PAD]\",\n",
    "            \"unk_token\":\"<unk>\",\n",
    "        },\n",
    "\n",
    "    )\n",
    "\n",
    "    tokenizer.add_tokens(SCIENCE_TAG_TOKENS)\n",
    "    tokenizer.add_tokens(SCIENCE_TOKENS)\n",
    "    extra_tokens = []\n",
    "    # protein\n",
    "    for i in range(26):\n",
    "        extra_tokens.append(f\"<a>{chr(65 + i)}\")\n",
    "\n",
    "    # DNA, RNA, including ambiguous bases\n",
    "    for c in \"ACTGURYSWKMBDHVN\":\n",
    "        extra_tokens.append(f\"<d>{c}\")\n",
    "        extra_tokens.append(f\"<r>{c}\")\n",
    "\n",
    "    # materials, non-elements\n",
    "    for c in \"0123456789()+-\":\n",
    "        extra_tokens.append(f\"<i>{c}\")\n",
    "    for i in range(26):\n",
    "        extra_tokens.append(f\"<i>{chr(65 + i)}\")\n",
    "        extra_tokens.append(f\"<i>{chr(97 + i)}\")\n",
    "\n",
    "    tokenizer.add_tokens(extra_tokens)\n",
    "    tokenizer.split_special_tokens = True  # Ensure _tokenize() can access special tokens\n",
    "\n",
    "    logger.info(f\"Tokenizer has {len(tokenizer)} tokens\")\n",
    "\n",
    "    args.vocab_size=len(tokenizer)\n",
    "\n",
    "    return args, tokenizer\n",
    "\n",
    "args, tokenizer = get_args_and_tokenizer()\n",
    "print(type(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.vocab_size=130304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the extended trained model\n",
    "ckpt_dict = {}\n",
    "\n",
    "model = ScigptModel(args)\n",
    "model.decoder.resize_token_embeddings(args.vocab_size)\n",
    "model_dict = model.state_dict()\n",
    "print(f\"model_dict: {model_dict.keys()}\")\n",
    "print(model_dict['decoder.model.layers.0.mlp.gate_proj.weight'].shape)\n",
    "print(model_dict['decoder.model.layers.0.mlp.up_proj.weight'].shape)\n",
    "weight1_size=model_dict['decoder.model.layers.0.mlp.gate_proj.weight'].size(0)\n",
    "weight2_size=model_dict['decoder.model.layers.0.mlp.up_proj.weight'].size(0)\n",
    "layer0 = torch.load(os.path.join(args.save_dir, \"layer_00-model_00-model_states.pt\"), map_location=torch.device(\"cpu\"))\n",
    "for k, v in layer0.items():\n",
    "    if k=='word_embeddings.weight':\n",
    "        ckpt_dict['decoder.model.embed_tokens.weight'] = v\n",
    "\n",
    "for l in range(0, 32):\n",
    "    l_index = str(l + 1).zfill(2)\n",
    "    layer = torch.load(os.path.join(args.save_dir, f\"layer_{l_index}-model_00-model_states.pt\"), map_location=torch.device(\"cpu\"))\n",
    "    for k in layer:\n",
    "        if \"dummy\" in k or 'rotary_emb' in k:\n",
    "            continue\n",
    "        if k==\"self_attention.layernorm_qkv.layer_norm_weight\":\n",
    "            ckpt_dict[f\"decoder.model.layers.{l}.input_layernorm.weight\"] = layer[k]\n",
    "        elif k=='self_attention.layernorm_qkv.query_weight':\n",
    "            ckpt_dict[f\"decoder.model.layers.{l}.self_attn.q_proj.weight\"] = layer[k]\n",
    "        elif k=='self_attention.layernorm_qkv.key_weight':\n",
    "            ckpt_dict[f\"decoder.model.layers.{l}.self_attn.k_proj.weight\"] = layer[k]\n",
    "        elif k=='self_attention.layernorm_qkv.value_weight':\n",
    "            ckpt_dict[f\"decoder.model.layers.{l}.self_attn.v_proj.weight\"] = layer[k]\n",
    "        elif k=='self_attention.proj.weight':\n",
    "            ckpt_dict[f\"decoder.model.layers.{l}.self_attn.o_proj.weight\"] = layer[k]\n",
    "        elif k=='layernorm_mlp.layer_norm_weight':\n",
    "            ckpt_dict[f\"decoder.model.layers.{l}.post_attention_layernorm.weight\"] = layer[k]\n",
    "        elif k=='layernorm_mlp.fc1_weight':\n",
    "            weight1,weight2=torch.split(layer[k], [weight1_size, weight2_size], dim=0)\n",
    "            ckpt_dict[f\"decoder.model.layers.{l}.mlp.gate_proj.weight\"] = weight1\n",
    "            ckpt_dict[f\"decoder.model.layers.{l}.mlp.up_proj.weight\"] = weight2\n",
    "        elif k=='layernorm_mlp.fc2_weight':\n",
    "            ckpt_dict[f\"decoder.model.layers.{l}.mlp.down_proj.weight\"] = layer[k]\n",
    "    del layer\n",
    "\n",
    "layer = torch.load(os.path.join(args.save_dir, \"layer_33-model_00-model_states.pt\"), map_location=torch.device(\"cpu\"))\n",
    "ckpt_dict[\"decoder.model.norm.weight\"] = layer[\"norm.weight\"]\n",
    "\n",
    "layer = torch.load(os.path.join(args.save_dir, \"layer_34-model_00-model_states.pt\"), map_location=torch.device(\"cpu\"))\n",
    "ckpt_dict[\"decoder.lm_head.weight\"] = layer[\"lm_head.weight\"]\n",
    "\n",
    "print(f\"ckpt_dict: {ckpt_dict.keys()}\")\n",
    "model_dict.update(ckpt_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dict: odict_keys(['decoder.model.embed_tokens.weight', 'decoder.model.layers.0.self_attn.q_proj.weight', 'decoder.model.layers.0.self_attn.k_proj.weight', 'decoder.model.layers.0.self_attn.v_proj.weight', 'decoder.model.layers.0.self_attn.o_proj.weight', 'decoder.model.layers.0.mlp.gate_proj.weight', 'decoder.model.layers.0.mlp.up_proj.weight', 'decoder.model.layers.0.mlp.down_proj.weight', 'decoder.model.layers.0.input_layernorm.weight', 'decoder.model.layers.0.post_attention_layernorm.weight', 'decoder.model.layers.1.self_attn.q_proj.weight', 'decoder.model.layers.1.self_attn.k_proj.weight', 'decoder.model.layers.1.self_attn.v_proj.weight', 'decoder.model.layers.1.self_attn.o_proj.weight', 'decoder.model.layers.1.mlp.gate_proj.weight', 'decoder.model.layers.1.mlp.up_proj.weight', 'decoder.model.layers.1.mlp.down_proj.weight', 'decoder.model.layers.1.input_layernorm.weight', 'decoder.model.layers.1.post_attention_layernorm.weight', 'decoder.model.layers.2.self_attn.q_proj.weight', 'decoder.model.layers.2.self_attn.k_proj.weight', 'decoder.model.layers.2.self_attn.v_proj.weight', 'decoder.model.layers.2.self_attn.o_proj.weight', 'decoder.model.layers.2.mlp.gate_proj.weight', 'decoder.model.layers.2.mlp.up_proj.weight', 'decoder.model.layers.2.mlp.down_proj.weight', 'decoder.model.layers.2.input_layernorm.weight', 'decoder.model.layers.2.post_attention_layernorm.weight', 'decoder.model.layers.3.self_attn.q_proj.weight', 'decoder.model.layers.3.self_attn.k_proj.weight', 'decoder.model.layers.3.self_attn.v_proj.weight', 'decoder.model.layers.3.self_attn.o_proj.weight', 'decoder.model.layers.3.mlp.gate_proj.weight', 'decoder.model.layers.3.mlp.up_proj.weight', 'decoder.model.layers.3.mlp.down_proj.weight', 'decoder.model.layers.3.input_layernorm.weight', 'decoder.model.layers.3.post_attention_layernorm.weight', 'decoder.model.layers.4.self_attn.q_proj.weight', 'decoder.model.layers.4.self_attn.k_proj.weight', 'decoder.model.layers.4.self_attn.v_proj.weight', 'decoder.model.layers.4.self_attn.o_proj.weight', 'decoder.model.layers.4.mlp.gate_proj.weight', 'decoder.model.layers.4.mlp.up_proj.weight', 'decoder.model.layers.4.mlp.down_proj.weight', 'decoder.model.layers.4.input_layernorm.weight', 'decoder.model.layers.4.post_attention_layernorm.weight', 'decoder.model.layers.5.self_attn.q_proj.weight', 'decoder.model.layers.5.self_attn.k_proj.weight', 'decoder.model.layers.5.self_attn.v_proj.weight', 'decoder.model.layers.5.self_attn.o_proj.weight', 'decoder.model.layers.5.mlp.gate_proj.weight', 'decoder.model.layers.5.mlp.up_proj.weight', 'decoder.model.layers.5.mlp.down_proj.weight', 'decoder.model.layers.5.input_layernorm.weight', 'decoder.model.layers.5.post_attention_layernorm.weight', 'decoder.model.layers.6.self_attn.q_proj.weight', 'decoder.model.layers.6.self_attn.k_proj.weight', 'decoder.model.layers.6.self_attn.v_proj.weight', 'decoder.model.layers.6.self_attn.o_proj.weight', 'decoder.model.layers.6.mlp.gate_proj.weight', 'decoder.model.layers.6.mlp.up_proj.weight', 'decoder.model.layers.6.mlp.down_proj.weight', 'decoder.model.layers.6.input_layernorm.weight', 'decoder.model.layers.6.post_attention_layernorm.weight', 'decoder.model.layers.7.self_attn.q_proj.weight', 'decoder.model.layers.7.self_attn.k_proj.weight', 'decoder.model.layers.7.self_attn.v_proj.weight', 'decoder.model.layers.7.self_attn.o_proj.weight', 'decoder.model.layers.7.mlp.gate_proj.weight', 'decoder.model.layers.7.mlp.up_proj.weight', 'decoder.model.layers.7.mlp.down_proj.weight', 'decoder.model.layers.7.input_layernorm.weight', 'decoder.model.layers.7.post_attention_layernorm.weight', 'decoder.model.layers.8.self_attn.q_proj.weight', 'decoder.model.layers.8.self_attn.k_proj.weight', 'decoder.model.layers.8.self_attn.v_proj.weight', 'decoder.model.layers.8.self_attn.o_proj.weight', 'decoder.model.layers.8.mlp.gate_proj.weight', 'decoder.model.layers.8.mlp.up_proj.weight', 'decoder.model.layers.8.mlp.down_proj.weight', 'decoder.model.layers.8.input_layernorm.weight', 'decoder.model.layers.8.post_attention_layernorm.weight', 'decoder.model.layers.9.self_attn.q_proj.weight', 'decoder.model.layers.9.self_attn.k_proj.weight', 'decoder.model.layers.9.self_attn.v_proj.weight', 'decoder.model.layers.9.self_attn.o_proj.weight', 'decoder.model.layers.9.mlp.gate_proj.weight', 'decoder.model.layers.9.mlp.up_proj.weight', 'decoder.model.layers.9.mlp.down_proj.weight', 'decoder.model.layers.9.input_layernorm.weight', 'decoder.model.layers.9.post_attention_layernorm.weight', 'decoder.model.layers.10.self_attn.q_proj.weight', 'decoder.model.layers.10.self_attn.k_proj.weight', 'decoder.model.layers.10.self_attn.v_proj.weight', 'decoder.model.layers.10.self_attn.o_proj.weight', 'decoder.model.layers.10.mlp.gate_proj.weight', 'decoder.model.layers.10.mlp.up_proj.weight', 'decoder.model.layers.10.mlp.down_proj.weight', 'decoder.model.layers.10.input_layernorm.weight', 'decoder.model.layers.10.post_attention_layernorm.weight', 'decoder.model.layers.11.self_attn.q_proj.weight', 'decoder.model.layers.11.self_attn.k_proj.weight', 'decoder.model.layers.11.self_attn.v_proj.weight', 'decoder.model.layers.11.self_attn.o_proj.weight', 'decoder.model.layers.11.mlp.gate_proj.weight', 'decoder.model.layers.11.mlp.up_proj.weight', 'decoder.model.layers.11.mlp.down_proj.weight', 'decoder.model.layers.11.input_layernorm.weight', 'decoder.model.layers.11.post_attention_layernorm.weight', 'decoder.model.layers.12.self_attn.q_proj.weight', 'decoder.model.layers.12.self_attn.k_proj.weight', 'decoder.model.layers.12.self_attn.v_proj.weight', 'decoder.model.layers.12.self_attn.o_proj.weight', 'decoder.model.layers.12.mlp.gate_proj.weight', 'decoder.model.layers.12.mlp.up_proj.weight', 'decoder.model.layers.12.mlp.down_proj.weight', 'decoder.model.layers.12.input_layernorm.weight', 'decoder.model.layers.12.post_attention_layernorm.weight', 'decoder.model.layers.13.self_attn.q_proj.weight', 'decoder.model.layers.13.self_attn.k_proj.weight', 'decoder.model.layers.13.self_attn.v_proj.weight', 'decoder.model.layers.13.self_attn.o_proj.weight', 'decoder.model.layers.13.mlp.gate_proj.weight', 'decoder.model.layers.13.mlp.up_proj.weight', 'decoder.model.layers.13.mlp.down_proj.weight', 'decoder.model.layers.13.input_layernorm.weight', 'decoder.model.layers.13.post_attention_layernorm.weight', 'decoder.model.layers.14.self_attn.q_proj.weight', 'decoder.model.layers.14.self_attn.k_proj.weight', 'decoder.model.layers.14.self_attn.v_proj.weight', 'decoder.model.layers.14.self_attn.o_proj.weight', 'decoder.model.layers.14.mlp.gate_proj.weight', 'decoder.model.layers.14.mlp.up_proj.weight', 'decoder.model.layers.14.mlp.down_proj.weight', 'decoder.model.layers.14.input_layernorm.weight', 'decoder.model.layers.14.post_attention_layernorm.weight', 'decoder.model.layers.15.self_attn.q_proj.weight', 'decoder.model.layers.15.self_attn.k_proj.weight', 'decoder.model.layers.15.self_attn.v_proj.weight', 'decoder.model.layers.15.self_attn.o_proj.weight', 'decoder.model.layers.15.mlp.gate_proj.weight', 'decoder.model.layers.15.mlp.up_proj.weight', 'decoder.model.layers.15.mlp.down_proj.weight', 'decoder.model.layers.15.input_layernorm.weight', 'decoder.model.layers.15.post_attention_layernorm.weight', 'decoder.model.layers.16.self_attn.q_proj.weight', 'decoder.model.layers.16.self_attn.k_proj.weight', 'decoder.model.layers.16.self_attn.v_proj.weight', 'decoder.model.layers.16.self_attn.o_proj.weight', 'decoder.model.layers.16.mlp.gate_proj.weight', 'decoder.model.layers.16.mlp.up_proj.weight', 'decoder.model.layers.16.mlp.down_proj.weight', 'decoder.model.layers.16.input_layernorm.weight', 'decoder.model.layers.16.post_attention_layernorm.weight', 'decoder.model.layers.17.self_attn.q_proj.weight', 'decoder.model.layers.17.self_attn.k_proj.weight', 'decoder.model.layers.17.self_attn.v_proj.weight', 'decoder.model.layers.17.self_attn.o_proj.weight', 'decoder.model.layers.17.mlp.gate_proj.weight', 'decoder.model.layers.17.mlp.up_proj.weight', 'decoder.model.layers.17.mlp.down_proj.weight', 'decoder.model.layers.17.input_layernorm.weight', 'decoder.model.layers.17.post_attention_layernorm.weight', 'decoder.model.layers.18.self_attn.q_proj.weight', 'decoder.model.layers.18.self_attn.k_proj.weight', 'decoder.model.layers.18.self_attn.v_proj.weight', 'decoder.model.layers.18.self_attn.o_proj.weight', 'decoder.model.layers.18.mlp.gate_proj.weight', 'decoder.model.layers.18.mlp.up_proj.weight', 'decoder.model.layers.18.mlp.down_proj.weight', 'decoder.model.layers.18.input_layernorm.weight', 'decoder.model.layers.18.post_attention_layernorm.weight', 'decoder.model.layers.19.self_attn.q_proj.weight', 'decoder.model.layers.19.self_attn.k_proj.weight', 'decoder.model.layers.19.self_attn.v_proj.weight', 'decoder.model.layers.19.self_attn.o_proj.weight', 'decoder.model.layers.19.mlp.gate_proj.weight', 'decoder.model.layers.19.mlp.up_proj.weight', 'decoder.model.layers.19.mlp.down_proj.weight', 'decoder.model.layers.19.input_layernorm.weight', 'decoder.model.layers.19.post_attention_layernorm.weight', 'decoder.model.layers.20.self_attn.q_proj.weight', 'decoder.model.layers.20.self_attn.k_proj.weight', 'decoder.model.layers.20.self_attn.v_proj.weight', 'decoder.model.layers.20.self_attn.o_proj.weight', 'decoder.model.layers.20.mlp.gate_proj.weight', 'decoder.model.layers.20.mlp.up_proj.weight', 'decoder.model.layers.20.mlp.down_proj.weight', 'decoder.model.layers.20.input_layernorm.weight', 'decoder.model.layers.20.post_attention_layernorm.weight', 'decoder.model.layers.21.self_attn.q_proj.weight', 'decoder.model.layers.21.self_attn.k_proj.weight', 'decoder.model.layers.21.self_attn.v_proj.weight', 'decoder.model.layers.21.self_attn.o_proj.weight', 'decoder.model.layers.21.mlp.gate_proj.weight', 'decoder.model.layers.21.mlp.up_proj.weight', 'decoder.model.layers.21.mlp.down_proj.weight', 'decoder.model.layers.21.input_layernorm.weight', 'decoder.model.layers.21.post_attention_layernorm.weight', 'decoder.model.layers.22.self_attn.q_proj.weight', 'decoder.model.layers.22.self_attn.k_proj.weight', 'decoder.model.layers.22.self_attn.v_proj.weight', 'decoder.model.layers.22.self_attn.o_proj.weight', 'decoder.model.layers.22.mlp.gate_proj.weight', 'decoder.model.layers.22.mlp.up_proj.weight', 'decoder.model.layers.22.mlp.down_proj.weight', 'decoder.model.layers.22.input_layernorm.weight', 'decoder.model.layers.22.post_attention_layernorm.weight', 'decoder.model.layers.23.self_attn.q_proj.weight', 'decoder.model.layers.23.self_attn.k_proj.weight', 'decoder.model.layers.23.self_attn.v_proj.weight', 'decoder.model.layers.23.self_attn.o_proj.weight', 'decoder.model.layers.23.mlp.gate_proj.weight', 'decoder.model.layers.23.mlp.up_proj.weight', 'decoder.model.layers.23.mlp.down_proj.weight', 'decoder.model.layers.23.input_layernorm.weight', 'decoder.model.layers.23.post_attention_layernorm.weight', 'decoder.model.layers.24.self_attn.q_proj.weight', 'decoder.model.layers.24.self_attn.k_proj.weight', 'decoder.model.layers.24.self_attn.v_proj.weight', 'decoder.model.layers.24.self_attn.o_proj.weight', 'decoder.model.layers.24.mlp.gate_proj.weight', 'decoder.model.layers.24.mlp.up_proj.weight', 'decoder.model.layers.24.mlp.down_proj.weight', 'decoder.model.layers.24.input_layernorm.weight', 'decoder.model.layers.24.post_attention_layernorm.weight', 'decoder.model.layers.25.self_attn.q_proj.weight', 'decoder.model.layers.25.self_attn.k_proj.weight', 'decoder.model.layers.25.self_attn.v_proj.weight', 'decoder.model.layers.25.self_attn.o_proj.weight', 'decoder.model.layers.25.mlp.gate_proj.weight', 'decoder.model.layers.25.mlp.up_proj.weight', 'decoder.model.layers.25.mlp.down_proj.weight', 'decoder.model.layers.25.input_layernorm.weight', 'decoder.model.layers.25.post_attention_layernorm.weight', 'decoder.model.layers.26.self_attn.q_proj.weight', 'decoder.model.layers.26.self_attn.k_proj.weight', 'decoder.model.layers.26.self_attn.v_proj.weight', 'decoder.model.layers.26.self_attn.o_proj.weight', 'decoder.model.layers.26.mlp.gate_proj.weight', 'decoder.model.layers.26.mlp.up_proj.weight', 'decoder.model.layers.26.mlp.down_proj.weight', 'decoder.model.layers.26.input_layernorm.weight', 'decoder.model.layers.26.post_attention_layernorm.weight', 'decoder.model.layers.27.self_attn.q_proj.weight', 'decoder.model.layers.27.self_attn.k_proj.weight', 'decoder.model.layers.27.self_attn.v_proj.weight', 'decoder.model.layers.27.self_attn.o_proj.weight', 'decoder.model.layers.27.mlp.gate_proj.weight', 'decoder.model.layers.27.mlp.up_proj.weight', 'decoder.model.layers.27.mlp.down_proj.weight', 'decoder.model.layers.27.input_layernorm.weight', 'decoder.model.layers.27.post_attention_layernorm.weight', 'decoder.model.layers.28.self_attn.q_proj.weight', 'decoder.model.layers.28.self_attn.k_proj.weight', 'decoder.model.layers.28.self_attn.v_proj.weight', 'decoder.model.layers.28.self_attn.o_proj.weight', 'decoder.model.layers.28.mlp.gate_proj.weight', 'decoder.model.layers.28.mlp.up_proj.weight', 'decoder.model.layers.28.mlp.down_proj.weight', 'decoder.model.layers.28.input_layernorm.weight', 'decoder.model.layers.28.post_attention_layernorm.weight', 'decoder.model.layers.29.self_attn.q_proj.weight', 'decoder.model.layers.29.self_attn.k_proj.weight', 'decoder.model.layers.29.self_attn.v_proj.weight', 'decoder.model.layers.29.self_attn.o_proj.weight', 'decoder.model.layers.29.mlp.gate_proj.weight', 'decoder.model.layers.29.mlp.up_proj.weight', 'decoder.model.layers.29.mlp.down_proj.weight', 'decoder.model.layers.29.input_layernorm.weight', 'decoder.model.layers.29.post_attention_layernorm.weight', 'decoder.model.layers.30.self_attn.q_proj.weight', 'decoder.model.layers.30.self_attn.k_proj.weight', 'decoder.model.layers.30.self_attn.v_proj.weight', 'decoder.model.layers.30.self_attn.o_proj.weight', 'decoder.model.layers.30.mlp.gate_proj.weight', 'decoder.model.layers.30.mlp.up_proj.weight', 'decoder.model.layers.30.mlp.down_proj.weight', 'decoder.model.layers.30.input_layernorm.weight', 'decoder.model.layers.30.post_attention_layernorm.weight', 'decoder.model.layers.31.self_attn.q_proj.weight', 'decoder.model.layers.31.self_attn.k_proj.weight', 'decoder.model.layers.31.self_attn.v_proj.weight', 'decoder.model.layers.31.self_attn.o_proj.weight', 'decoder.model.layers.31.mlp.gate_proj.weight', 'decoder.model.layers.31.mlp.up_proj.weight', 'decoder.model.layers.31.mlp.down_proj.weight', 'decoder.model.layers.31.input_layernorm.weight', 'decoder.model.layers.31.post_attention_layernorm.weight', 'decoder.model.layers.32.self_attn.q_proj.weight', 'decoder.model.layers.32.self_attn.k_proj.weight', 'decoder.model.layers.32.self_attn.v_proj.weight', 'decoder.model.layers.32.self_attn.o_proj.weight', 'decoder.model.layers.32.mlp.gate_proj.weight', 'decoder.model.layers.32.mlp.up_proj.weight', 'decoder.model.layers.32.mlp.down_proj.weight', 'decoder.model.layers.32.input_layernorm.weight', 'decoder.model.layers.32.post_attention_layernorm.weight', 'decoder.model.layers.33.self_attn.q_proj.weight', 'decoder.model.layers.33.self_attn.k_proj.weight', 'decoder.model.layers.33.self_attn.v_proj.weight', 'decoder.model.layers.33.self_attn.o_proj.weight', 'decoder.model.layers.33.mlp.gate_proj.weight', 'decoder.model.layers.33.mlp.up_proj.weight', 'decoder.model.layers.33.mlp.down_proj.weight', 'decoder.model.layers.33.input_layernorm.weight', 'decoder.model.layers.33.post_attention_layernorm.weight', 'decoder.model.layers.34.self_attn.q_proj.weight', 'decoder.model.layers.34.self_attn.k_proj.weight', 'decoder.model.layers.34.self_attn.v_proj.weight', 'decoder.model.layers.34.self_attn.o_proj.weight', 'decoder.model.layers.34.mlp.gate_proj.weight', 'decoder.model.layers.34.mlp.up_proj.weight', 'decoder.model.layers.34.mlp.down_proj.weight', 'decoder.model.layers.34.input_layernorm.weight', 'decoder.model.layers.34.post_attention_layernorm.weight', 'decoder.model.layers.35.self_attn.q_proj.weight', 'decoder.model.layers.35.self_attn.k_proj.weight', 'decoder.model.layers.35.self_attn.v_proj.weight', 'decoder.model.layers.35.self_attn.o_proj.weight', 'decoder.model.layers.35.mlp.gate_proj.weight', 'decoder.model.layers.35.mlp.up_proj.weight', 'decoder.model.layers.35.mlp.down_proj.weight', 'decoder.model.layers.35.input_layernorm.weight', 'decoder.model.layers.35.post_attention_layernorm.weight', 'decoder.model.layers.36.self_attn.q_proj.weight', 'decoder.model.layers.36.self_attn.k_proj.weight', 'decoder.model.layers.36.self_attn.v_proj.weight', 'decoder.model.layers.36.self_attn.o_proj.weight', 'decoder.model.layers.36.mlp.gate_proj.weight', 'decoder.model.layers.36.mlp.up_proj.weight', 'decoder.model.layers.36.mlp.down_proj.weight', 'decoder.model.layers.36.input_layernorm.weight', 'decoder.model.layers.36.post_attention_layernorm.weight', 'decoder.model.layers.37.self_attn.q_proj.weight', 'decoder.model.layers.37.self_attn.k_proj.weight', 'decoder.model.layers.37.self_attn.v_proj.weight', 'decoder.model.layers.37.self_attn.o_proj.weight', 'decoder.model.layers.37.mlp.gate_proj.weight', 'decoder.model.layers.37.mlp.up_proj.weight', 'decoder.model.layers.37.mlp.down_proj.weight', 'decoder.model.layers.37.input_layernorm.weight', 'decoder.model.layers.37.post_attention_layernorm.weight', 'decoder.model.layers.38.self_attn.q_proj.weight', 'decoder.model.layers.38.self_attn.k_proj.weight', 'decoder.model.layers.38.self_attn.v_proj.weight', 'decoder.model.layers.38.self_attn.o_proj.weight', 'decoder.model.layers.38.mlp.gate_proj.weight', 'decoder.model.layers.38.mlp.up_proj.weight', 'decoder.model.layers.38.mlp.down_proj.weight', 'decoder.model.layers.38.input_layernorm.weight', 'decoder.model.layers.38.post_attention_layernorm.weight', 'decoder.model.layers.39.self_attn.q_proj.weight', 'decoder.model.layers.39.self_attn.k_proj.weight', 'decoder.model.layers.39.self_attn.v_proj.weight', 'decoder.model.layers.39.self_attn.o_proj.weight', 'decoder.model.layers.39.mlp.gate_proj.weight', 'decoder.model.layers.39.mlp.up_proj.weight', 'decoder.model.layers.39.mlp.down_proj.weight', 'decoder.model.layers.39.input_layernorm.weight', 'decoder.model.layers.39.post_attention_layernorm.weight', 'decoder.model.layers.40.self_attn.q_proj.weight', 'decoder.model.layers.40.self_attn.k_proj.weight', 'decoder.model.layers.40.self_attn.v_proj.weight', 'decoder.model.layers.40.self_attn.o_proj.weight', 'decoder.model.layers.40.mlp.gate_proj.weight', 'decoder.model.layers.40.mlp.up_proj.weight', 'decoder.model.layers.40.mlp.down_proj.weight', 'decoder.model.layers.40.input_layernorm.weight', 'decoder.model.layers.40.post_attention_layernorm.weight', 'decoder.model.layers.41.self_attn.q_proj.weight', 'decoder.model.layers.41.self_attn.k_proj.weight', 'decoder.model.layers.41.self_attn.v_proj.weight', 'decoder.model.layers.41.self_attn.o_proj.weight', 'decoder.model.layers.41.mlp.gate_proj.weight', 'decoder.model.layers.41.mlp.up_proj.weight', 'decoder.model.layers.41.mlp.down_proj.weight', 'decoder.model.layers.41.input_layernorm.weight', 'decoder.model.layers.41.post_attention_layernorm.weight', 'decoder.model.layers.42.self_attn.q_proj.weight', 'decoder.model.layers.42.self_attn.k_proj.weight', 'decoder.model.layers.42.self_attn.v_proj.weight', 'decoder.model.layers.42.self_attn.o_proj.weight', 'decoder.model.layers.42.mlp.gate_proj.weight', 'decoder.model.layers.42.mlp.up_proj.weight', 'decoder.model.layers.42.mlp.down_proj.weight', 'decoder.model.layers.42.input_layernorm.weight', 'decoder.model.layers.42.post_attention_layernorm.weight', 'decoder.model.layers.43.self_attn.q_proj.weight', 'decoder.model.layers.43.self_attn.k_proj.weight', 'decoder.model.layers.43.self_attn.v_proj.weight', 'decoder.model.layers.43.self_attn.o_proj.weight', 'decoder.model.layers.43.mlp.gate_proj.weight', 'decoder.model.layers.43.mlp.up_proj.weight', 'decoder.model.layers.43.mlp.down_proj.weight', 'decoder.model.layers.43.input_layernorm.weight', 'decoder.model.layers.43.post_attention_layernorm.weight', 'decoder.model.layers.44.self_attn.q_proj.weight', 'decoder.model.layers.44.self_attn.k_proj.weight', 'decoder.model.layers.44.self_attn.v_proj.weight', 'decoder.model.layers.44.self_attn.o_proj.weight', 'decoder.model.layers.44.mlp.gate_proj.weight', 'decoder.model.layers.44.mlp.up_proj.weight', 'decoder.model.layers.44.mlp.down_proj.weight', 'decoder.model.layers.44.input_layernorm.weight', 'decoder.model.layers.44.post_attention_layernorm.weight', 'decoder.model.layers.45.self_attn.q_proj.weight', 'decoder.model.layers.45.self_attn.k_proj.weight', 'decoder.model.layers.45.self_attn.v_proj.weight', 'decoder.model.layers.45.self_attn.o_proj.weight', 'decoder.model.layers.45.mlp.gate_proj.weight', 'decoder.model.layers.45.mlp.up_proj.weight', 'decoder.model.layers.45.mlp.down_proj.weight', 'decoder.model.layers.45.input_layernorm.weight', 'decoder.model.layers.45.post_attention_layernorm.weight', 'decoder.model.layers.46.self_attn.q_proj.weight', 'decoder.model.layers.46.self_attn.k_proj.weight', 'decoder.model.layers.46.self_attn.v_proj.weight', 'decoder.model.layers.46.self_attn.o_proj.weight', 'decoder.model.layers.46.mlp.gate_proj.weight', 'decoder.model.layers.46.mlp.up_proj.weight', 'decoder.model.layers.46.mlp.down_proj.weight', 'decoder.model.layers.46.input_layernorm.weight', 'decoder.model.layers.46.post_attention_layernorm.weight', 'decoder.model.layers.47.self_attn.q_proj.weight', 'decoder.model.layers.47.self_attn.k_proj.weight', 'decoder.model.layers.47.self_attn.v_proj.weight', 'decoder.model.layers.47.self_attn.o_proj.weight', 'decoder.model.layers.47.mlp.gate_proj.weight', 'decoder.model.layers.47.mlp.up_proj.weight', 'decoder.model.layers.47.mlp.down_proj.weight', 'decoder.model.layers.47.input_layernorm.weight', 'decoder.model.layers.47.post_attention_layernorm.weight', 'decoder.model.layers.48.self_attn.q_proj.weight', 'decoder.model.layers.48.self_attn.k_proj.weight', 'decoder.model.layers.48.self_attn.v_proj.weight', 'decoder.model.layers.48.self_attn.o_proj.weight', 'decoder.model.layers.48.mlp.gate_proj.weight', 'decoder.model.layers.48.mlp.up_proj.weight', 'decoder.model.layers.48.mlp.down_proj.weight', 'decoder.model.layers.48.input_layernorm.weight', 'decoder.model.layers.48.post_attention_layernorm.weight', 'decoder.model.layers.49.self_attn.q_proj.weight', 'decoder.model.layers.49.self_attn.k_proj.weight', 'decoder.model.layers.49.self_attn.v_proj.weight', 'decoder.model.layers.49.self_attn.o_proj.weight', 'decoder.model.layers.49.mlp.gate_proj.weight', 'decoder.model.layers.49.mlp.up_proj.weight', 'decoder.model.layers.49.mlp.down_proj.weight', 'decoder.model.layers.49.input_layernorm.weight', 'decoder.model.layers.49.post_attention_layernorm.weight', 'decoder.model.layers.50.self_attn.q_proj.weight', 'decoder.model.layers.50.self_attn.k_proj.weight', 'decoder.model.layers.50.self_attn.v_proj.weight', 'decoder.model.layers.50.self_attn.o_proj.weight', 'decoder.model.layers.50.mlp.gate_proj.weight', 'decoder.model.layers.50.mlp.up_proj.weight', 'decoder.model.layers.50.mlp.down_proj.weight', 'decoder.model.layers.50.input_layernorm.weight', 'decoder.model.layers.50.post_attention_layernorm.weight', 'decoder.model.layers.51.self_attn.q_proj.weight', 'decoder.model.layers.51.self_attn.k_proj.weight', 'decoder.model.layers.51.self_attn.v_proj.weight', 'decoder.model.layers.51.self_attn.o_proj.weight', 'decoder.model.layers.51.mlp.gate_proj.weight', 'decoder.model.layers.51.mlp.up_proj.weight', 'decoder.model.layers.51.mlp.down_proj.weight', 'decoder.model.layers.51.input_layernorm.weight', 'decoder.model.layers.51.post_attention_layernorm.weight', 'decoder.model.layers.52.self_attn.q_proj.weight', 'decoder.model.layers.52.self_attn.k_proj.weight', 'decoder.model.layers.52.self_attn.v_proj.weight', 'decoder.model.layers.52.self_attn.o_proj.weight', 'decoder.model.layers.52.mlp.gate_proj.weight', 'decoder.model.layers.52.mlp.up_proj.weight', 'decoder.model.layers.52.mlp.down_proj.weight', 'decoder.model.layers.52.input_layernorm.weight', 'decoder.model.layers.52.post_attention_layernorm.weight', 'decoder.model.layers.53.self_attn.q_proj.weight', 'decoder.model.layers.53.self_attn.k_proj.weight', 'decoder.model.layers.53.self_attn.v_proj.weight', 'decoder.model.layers.53.self_attn.o_proj.weight', 'decoder.model.layers.53.mlp.gate_proj.weight', 'decoder.model.layers.53.mlp.up_proj.weight', 'decoder.model.layers.53.mlp.down_proj.weight', 'decoder.model.layers.53.input_layernorm.weight', 'decoder.model.layers.53.post_attention_layernorm.weight', 'decoder.model.layers.54.self_attn.q_proj.weight', 'decoder.model.layers.54.self_attn.k_proj.weight', 'decoder.model.layers.54.self_attn.v_proj.weight', 'decoder.model.layers.54.self_attn.o_proj.weight', 'decoder.model.layers.54.mlp.gate_proj.weight', 'decoder.model.layers.54.mlp.up_proj.weight', 'decoder.model.layers.54.mlp.down_proj.weight', 'decoder.model.layers.54.input_layernorm.weight', 'decoder.model.layers.54.post_attention_layernorm.weight', 'decoder.model.layers.55.self_attn.q_proj.weight', 'decoder.model.layers.55.self_attn.k_proj.weight', 'decoder.model.layers.55.self_attn.v_proj.weight', 'decoder.model.layers.55.self_attn.o_proj.weight', 'decoder.model.layers.55.mlp.gate_proj.weight', 'decoder.model.layers.55.mlp.up_proj.weight', 'decoder.model.layers.55.mlp.down_proj.weight', 'decoder.model.layers.55.input_layernorm.weight', 'decoder.model.layers.55.post_attention_layernorm.weight', 'decoder.model.layers.56.self_attn.q_proj.weight', 'decoder.model.layers.56.self_attn.k_proj.weight', 'decoder.model.layers.56.self_attn.v_proj.weight', 'decoder.model.layers.56.self_attn.o_proj.weight', 'decoder.model.layers.56.mlp.gate_proj.weight', 'decoder.model.layers.56.mlp.up_proj.weight', 'decoder.model.layers.56.mlp.down_proj.weight', 'decoder.model.layers.56.input_layernorm.weight', 'decoder.model.layers.56.post_attention_layernorm.weight', 'decoder.model.layers.57.self_attn.q_proj.weight', 'decoder.model.layers.57.self_attn.k_proj.weight', 'decoder.model.layers.57.self_attn.v_proj.weight', 'decoder.model.layers.57.self_attn.o_proj.weight', 'decoder.model.layers.57.mlp.gate_proj.weight', 'decoder.model.layers.57.mlp.up_proj.weight', 'decoder.model.layers.57.mlp.down_proj.weight', 'decoder.model.layers.57.input_layernorm.weight', 'decoder.model.layers.57.post_attention_layernorm.weight', 'decoder.model.layers.58.self_attn.q_proj.weight', 'decoder.model.layers.58.self_attn.k_proj.weight', 'decoder.model.layers.58.self_attn.v_proj.weight', 'decoder.model.layers.58.self_attn.o_proj.weight', 'decoder.model.layers.58.mlp.gate_proj.weight', 'decoder.model.layers.58.mlp.up_proj.weight', 'decoder.model.layers.58.mlp.down_proj.weight', 'decoder.model.layers.58.input_layernorm.weight', 'decoder.model.layers.58.post_attention_layernorm.weight', 'decoder.model.layers.59.self_attn.q_proj.weight', 'decoder.model.layers.59.self_attn.k_proj.weight', 'decoder.model.layers.59.self_attn.v_proj.weight', 'decoder.model.layers.59.self_attn.o_proj.weight', 'decoder.model.layers.59.mlp.gate_proj.weight', 'decoder.model.layers.59.mlp.up_proj.weight', 'decoder.model.layers.59.mlp.down_proj.weight', 'decoder.model.layers.59.input_layernorm.weight', 'decoder.model.layers.59.post_attention_layernorm.weight', 'decoder.model.layers.60.self_attn.q_proj.weight', 'decoder.model.layers.60.self_attn.k_proj.weight', 'decoder.model.layers.60.self_attn.v_proj.weight', 'decoder.model.layers.60.self_attn.o_proj.weight', 'decoder.model.layers.60.mlp.gate_proj.weight', 'decoder.model.layers.60.mlp.up_proj.weight', 'decoder.model.layers.60.mlp.down_proj.weight', 'decoder.model.layers.60.input_layernorm.weight', 'decoder.model.layers.60.post_attention_layernorm.weight', 'decoder.model.layers.61.self_attn.q_proj.weight', 'decoder.model.layers.61.self_attn.k_proj.weight', 'decoder.model.layers.61.self_attn.v_proj.weight', 'decoder.model.layers.61.self_attn.o_proj.weight', 'decoder.model.layers.61.mlp.gate_proj.weight', 'decoder.model.layers.61.mlp.up_proj.weight', 'decoder.model.layers.61.mlp.down_proj.weight', 'decoder.model.layers.61.input_layernorm.weight', 'decoder.model.layers.61.post_attention_layernorm.weight', 'decoder.model.layers.62.self_attn.q_proj.weight', 'decoder.model.layers.62.self_attn.k_proj.weight', 'decoder.model.layers.62.self_attn.v_proj.weight', 'decoder.model.layers.62.self_attn.o_proj.weight', 'decoder.model.layers.62.mlp.gate_proj.weight', 'decoder.model.layers.62.mlp.up_proj.weight', 'decoder.model.layers.62.mlp.down_proj.weight', 'decoder.model.layers.62.input_layernorm.weight', 'decoder.model.layers.62.post_attention_layernorm.weight', 'decoder.model.layers.63.self_attn.q_proj.weight', 'decoder.model.layers.63.self_attn.k_proj.weight', 'decoder.model.layers.63.self_attn.v_proj.weight', 'decoder.model.layers.63.self_attn.o_proj.weight', 'decoder.model.layers.63.mlp.gate_proj.weight', 'decoder.model.layers.63.mlp.up_proj.weight', 'decoder.model.layers.63.mlp.down_proj.weight', 'decoder.model.layers.63.input_layernorm.weight', 'decoder.model.layers.63.post_attention_layernorm.weight', 'decoder.model.layers.64.self_attn.q_proj.weight', 'decoder.model.layers.64.self_attn.k_proj.weight', 'decoder.model.layers.64.self_attn.v_proj.weight', 'decoder.model.layers.64.self_attn.o_proj.weight', 'decoder.model.layers.64.mlp.gate_proj.weight', 'decoder.model.layers.64.mlp.up_proj.weight', 'decoder.model.layers.64.mlp.down_proj.weight', 'decoder.model.layers.64.input_layernorm.weight', 'decoder.model.layers.64.post_attention_layernorm.weight', 'decoder.model.layers.65.self_attn.q_proj.weight', 'decoder.model.layers.65.self_attn.k_proj.weight', 'decoder.model.layers.65.self_attn.v_proj.weight', 'decoder.model.layers.65.self_attn.o_proj.weight', 'decoder.model.layers.65.mlp.gate_proj.weight', 'decoder.model.layers.65.mlp.up_proj.weight', 'decoder.model.layers.65.mlp.down_proj.weight', 'decoder.model.layers.65.input_layernorm.weight', 'decoder.model.layers.65.post_attention_layernorm.weight', 'decoder.model.layers.66.self_attn.q_proj.weight', 'decoder.model.layers.66.self_attn.k_proj.weight', 'decoder.model.layers.66.self_attn.v_proj.weight', 'decoder.model.layers.66.self_attn.o_proj.weight', 'decoder.model.layers.66.mlp.gate_proj.weight', 'decoder.model.layers.66.mlp.up_proj.weight', 'decoder.model.layers.66.mlp.down_proj.weight', 'decoder.model.layers.66.input_layernorm.weight', 'decoder.model.layers.66.post_attention_layernorm.weight', 'decoder.model.layers.67.self_attn.q_proj.weight', 'decoder.model.layers.67.self_attn.k_proj.weight', 'decoder.model.layers.67.self_attn.v_proj.weight', 'decoder.model.layers.67.self_attn.o_proj.weight', 'decoder.model.layers.67.mlp.gate_proj.weight', 'decoder.model.layers.67.mlp.up_proj.weight', 'decoder.model.layers.67.mlp.down_proj.weight', 'decoder.model.layers.67.input_layernorm.weight', 'decoder.model.layers.67.post_attention_layernorm.weight', 'decoder.model.layers.68.self_attn.q_proj.weight', 'decoder.model.layers.68.self_attn.k_proj.weight', 'decoder.model.layers.68.self_attn.v_proj.weight', 'decoder.model.layers.68.self_attn.o_proj.weight', 'decoder.model.layers.68.mlp.gate_proj.weight', 'decoder.model.layers.68.mlp.up_proj.weight', 'decoder.model.layers.68.mlp.down_proj.weight', 'decoder.model.layers.68.input_layernorm.weight', 'decoder.model.layers.68.post_attention_layernorm.weight', 'decoder.model.layers.69.self_attn.q_proj.weight', 'decoder.model.layers.69.self_attn.k_proj.weight', 'decoder.model.layers.69.self_attn.v_proj.weight', 'decoder.model.layers.69.self_attn.o_proj.weight', 'decoder.model.layers.69.mlp.gate_proj.weight', 'decoder.model.layers.69.mlp.up_proj.weight', 'decoder.model.layers.69.mlp.down_proj.weight', 'decoder.model.layers.69.input_layernorm.weight', 'decoder.model.layers.69.post_attention_layernorm.weight', 'decoder.model.layers.70.self_attn.q_proj.weight', 'decoder.model.layers.70.self_attn.k_proj.weight', 'decoder.model.layers.70.self_attn.v_proj.weight', 'decoder.model.layers.70.self_attn.o_proj.weight', 'decoder.model.layers.70.mlp.gate_proj.weight', 'decoder.model.layers.70.mlp.up_proj.weight', 'decoder.model.layers.70.mlp.down_proj.weight', 'decoder.model.layers.70.input_layernorm.weight', 'decoder.model.layers.70.post_attention_layernorm.weight', 'decoder.model.layers.71.self_attn.q_proj.weight', 'decoder.model.layers.71.self_attn.k_proj.weight', 'decoder.model.layers.71.self_attn.v_proj.weight', 'decoder.model.layers.71.self_attn.o_proj.weight', 'decoder.model.layers.71.mlp.gate_proj.weight', 'decoder.model.layers.71.mlp.up_proj.weight', 'decoder.model.layers.71.mlp.down_proj.weight', 'decoder.model.layers.71.input_layernorm.weight', 'decoder.model.layers.71.post_attention_layernorm.weight', 'decoder.model.layers.72.self_attn.q_proj.weight', 'decoder.model.layers.72.self_attn.k_proj.weight', 'decoder.model.layers.72.self_attn.v_proj.weight', 'decoder.model.layers.72.self_attn.o_proj.weight', 'decoder.model.layers.72.mlp.gate_proj.weight', 'decoder.model.layers.72.mlp.up_proj.weight', 'decoder.model.layers.72.mlp.down_proj.weight', 'decoder.model.layers.72.input_layernorm.weight', 'decoder.model.layers.72.post_attention_layernorm.weight', 'decoder.model.layers.73.self_attn.q_proj.weight', 'decoder.model.layers.73.self_attn.k_proj.weight', 'decoder.model.layers.73.self_attn.v_proj.weight', 'decoder.model.layers.73.self_attn.o_proj.weight', 'decoder.model.layers.73.mlp.gate_proj.weight', 'decoder.model.layers.73.mlp.up_proj.weight', 'decoder.model.layers.73.mlp.down_proj.weight', 'decoder.model.layers.73.input_layernorm.weight', 'decoder.model.layers.73.post_attention_layernorm.weight', 'decoder.model.layers.74.self_attn.q_proj.weight', 'decoder.model.layers.74.self_attn.k_proj.weight', 'decoder.model.layers.74.self_attn.v_proj.weight', 'decoder.model.layers.74.self_attn.o_proj.weight', 'decoder.model.layers.74.mlp.gate_proj.weight', 'decoder.model.layers.74.mlp.up_proj.weight', 'decoder.model.layers.74.mlp.down_proj.weight', 'decoder.model.layers.74.input_layernorm.weight', 'decoder.model.layers.74.post_attention_layernorm.weight', 'decoder.model.layers.75.self_attn.q_proj.weight', 'decoder.model.layers.75.self_attn.k_proj.weight', 'decoder.model.layers.75.self_attn.v_proj.weight', 'decoder.model.layers.75.self_attn.o_proj.weight', 'decoder.model.layers.75.mlp.gate_proj.weight', 'decoder.model.layers.75.mlp.up_proj.weight', 'decoder.model.layers.75.mlp.down_proj.weight', 'decoder.model.layers.75.input_layernorm.weight', 'decoder.model.layers.75.post_attention_layernorm.weight', 'decoder.model.layers.76.self_attn.q_proj.weight', 'decoder.model.layers.76.self_attn.k_proj.weight', 'decoder.model.layers.76.self_attn.v_proj.weight', 'decoder.model.layers.76.self_attn.o_proj.weight', 'decoder.model.layers.76.mlp.gate_proj.weight', 'decoder.model.layers.76.mlp.up_proj.weight', 'decoder.model.layers.76.mlp.down_proj.weight', 'decoder.model.layers.76.input_layernorm.weight', 'decoder.model.layers.76.post_attention_layernorm.weight', 'decoder.model.layers.77.self_attn.q_proj.weight', 'decoder.model.layers.77.self_attn.k_proj.weight', 'decoder.model.layers.77.self_attn.v_proj.weight', 'decoder.model.layers.77.self_attn.o_proj.weight', 'decoder.model.layers.77.mlp.gate_proj.weight', 'decoder.model.layers.77.mlp.up_proj.weight', 'decoder.model.layers.77.mlp.down_proj.weight', 'decoder.model.layers.77.input_layernorm.weight', 'decoder.model.layers.77.post_attention_layernorm.weight', 'decoder.model.layers.78.self_attn.q_proj.weight', 'decoder.model.layers.78.self_attn.k_proj.weight', 'decoder.model.layers.78.self_attn.v_proj.weight', 'decoder.model.layers.78.self_attn.o_proj.weight', 'decoder.model.layers.78.mlp.gate_proj.weight', 'decoder.model.layers.78.mlp.up_proj.weight', 'decoder.model.layers.78.mlp.down_proj.weight', 'decoder.model.layers.78.input_layernorm.weight', 'decoder.model.layers.78.post_attention_layernorm.weight', 'decoder.model.layers.79.self_attn.q_proj.weight', 'decoder.model.layers.79.self_attn.k_proj.weight', 'decoder.model.layers.79.self_attn.v_proj.weight', 'decoder.model.layers.79.self_attn.o_proj.weight', 'decoder.model.layers.79.mlp.gate_proj.weight', 'decoder.model.layers.79.mlp.up_proj.weight', 'decoder.model.layers.79.mlp.down_proj.weight', 'decoder.model.layers.79.input_layernorm.weight', 'decoder.model.layers.79.post_attention_layernorm.weight', 'decoder.model.norm.weight', 'decoder.lm_head.weight'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'norm.weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m layer\n\u001b[1;32m     22\u001b[0m layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39msave_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_33-model_states.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m), map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 23\u001b[0m ckpt_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder.model.norm.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnorm.weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39msave_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_34-model_states.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m), map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     26\u001b[0m ckpt_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder.lm_head.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m layer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlm_head.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'norm.weight'"
     ]
    }
   ],
   "source": [
    "ckpt_dict = {}\n",
    "# Load the original llama3 model\n",
    "model = ScigptModel(args)\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "print(f\"model_dict: {model_dict.keys()}\")\n",
    "\n",
    "layer0 = torch.load(os.path.join(args.save_dir, \"layer_00-model_states.pt\"), map_location=torch.device(\"cpu\"))\n",
    "for k, v in layer0.items():\n",
    "    new_k = \"decoder.model.\" + k\n",
    "    ckpt_dict[new_k] = v\n",
    "\n",
    "for l in range(0, 80):\n",
    "    l_index = str(l + 1).zfill(2)\n",
    "    layer = torch.load(os.path.join(args.save_dir, f\"layer_{l_index}-model_states.pt\"), map_location=torch.device(\"cpu\"))\n",
    "    for k in layer:\n",
    "        if \"dummy\" in k or 'rotary_emb' in k:\n",
    "            continue\n",
    "        ckpt_dict[f\"decoder.model.layers.{l}.{k}\"] = layer[k]\n",
    "    del layer\n",
    "\n",
    "layer = torch.load(os.path.join(args.save_dir, \"layer_33-model_states.pt\"), map_location=torch.device(\"cpu\"))\n",
    "ckpt_dict[\"decoder.model.norm.weight\"] = layer[\"norm.weight\"]\n",
    "\n",
    "layer = torch.load(os.path.join(args.save_dir, \"layer_34-model_states.pt\"), map_location=torch.device(\"cpu\"))\n",
    "ckpt_dict[\"decoder.lm_head.weight\"] = layer[\"lm_head.weight\"]\n",
    "\n",
    "print(f\"ckpt_dict: {ckpt_dict.keys()}\")\n",
    "model_dict.update(ckpt_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = model.to(torch.bfloat16).to(device)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "from sfm.data.prot_data.util import bstr2obj\n",
    "# load data\n",
    "file_path='/data/peiran/blob/hai1data/sfm/nlm/llama3_300B/valid_lmdb/valid.patent.v2.txt.lmdb'\n",
    "env = lmdb.open(\n",
    "    file_path, subdir=True, readonly=True, lock=False, readahead=False\n",
    ")\n",
    "txn = env.begin(write=False)\n",
    "\n",
    "print(env.stat())\n",
    "count=0\n",
    "metadata = bstr2obj(txn.get(\"metadata\".encode()))\n",
    "cur_len, cur_keys = metadata[\"size\"], metadata[\"keys\"]\n",
    "print(cur_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Calculate loss\n",
    "print(metadata.keys())\n",
    "loss_list=[]\n",
    "print(metadata['processed_seq_len'])\n",
    "for key in cur_keys:\n",
    "    value = txn.get(str(key).encode())\n",
    "    input_ids = np.frombuffer(value, dtype=np.uint32)\n",
    "    input_tensor = torch.from_numpy(input_ids.astype(np.int64)).unsqueeze(0).to(device)\n",
    "    labels = input_tensor.clone()\n",
    "    out = model.decoder(input_tensor, labels=labels)\n",
    "    input_tensor.to(\"cpu\")\n",
    "    labels.to(\"cpu\")\n",
    "    print(out.loss.cpu().item())\n",
    "    loss_list.append(out.loss.cpu().item())\n",
    "    out = None\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    del out\n",
    "print(sum(loss_list) / len(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(input_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"Football is a \", return_tensors=\"pt\")\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.decoder.generate(\n",
    "    input_ids=torch.tensor(input_tensor).to(device),\n",
    "    num_beams=5,\n",
    "    max_new_tokens=512,\n",
    "    num_return_sequences=1,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.5,\n",
    ")\n",
    "res = tokenizer.decode(output.sequences[0], skip_special_tokens=False)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=torch.tensor(tokenizer.encode(\"Football is a \", return_tensors=\"pt\")).to(device)\n",
    "labels = input_ids.clone()\n",
    "out = model.decoder(input_ids,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.decoder.generate(\n",
    "    input_ids=torch.tensor(tokenizer.encode(\"Football is a \", return_tensors=\"pt\")).to(device),\n",
    "    num_beams=5,\n",
    "    max_new_tokens=512,\n",
    "    num_return_sequences=1,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.5,\n",
    ")\n",
    "res = tokenizer.decode(output.sequences[0], skip_special_tokens=False)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

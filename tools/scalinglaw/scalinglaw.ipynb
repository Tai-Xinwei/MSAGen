{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib.colors import Normalize  \n",
    "from matplotlib.colors import LogNorm  \n",
    "from matplotlib.ticker import FormatStrFormatter, LogFormatter  \n",
    "\n",
    "api = wandb.Api(timeout=300)\n",
    "runs = api.runs('microsoft-research-incubation/ds_mfmpre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_fit(xs, ys):\n",
    "    # xs, ys may each be a Python list or 1d numpy array of x and y values\n",
    "    model = LinearRegression()\n",
    "    model.fit(np.array(xs).reshape(-1, 1), np.array(ys).reshape(-1, 1))\n",
    "    slope, intercept = model.coef_[0][0], model.intercept_[0]\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = [\n",
    "            # \"bfm650m_data3_maskspan3_ddp4e5d16mask020drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2\", \n",
    "            \"bfm3B_data2_maskspan3_ddp2e5d16mask030drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2\", \n",
    "            \"scalinglaw5m\", \"scalinglaw10m\", \"scalinglaw50m\", \"scalinglaw100m\"]\n",
    "\n",
    "run_params = {\n",
    "    \"bfm650m_data3_maskspan3_ddp4e5d16mask020drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2\": 674973473,\n",
    "    \"bfm650m_data3_maskspan3_ddp4e5d16mask020drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2_2\": 674973473,\n",
    "    \"bfm3B_data2_maskspan3_ddp2e5d16mask030drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2\": 2890135076,\n",
    "    \"scalinglaw5m\": 6186754,\n",
    "    \"scalinglaw10m\": 36801538,\n",
    "    \"scalinglaw50m\": 57807878,\n",
    "    \"scalinglaw100m\": 120790028,\n",
    "}\n",
    "\n",
    "legend_names = {\n",
    "    \"bfm650m_data3_maskspan3_ddp4e5d16mask020drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2\": 'bfm650M',\n",
    "    \"bfm650m_data3_maskspan3_ddp4e5d16mask020drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2_2\": 'bfm650M',\n",
    "    \"bfm3B_data2_maskspan3_ddp2e5d16mask030drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2\": 'bfm3B',\n",
    "    \"scalinglaw5m\": 'bfm6M',\n",
    "    \"scalinglaw10m\": 'bfm37M',\n",
    "    \"scalinglaw50m\": 'bfm58M',\n",
    "    \"scalinglaw100m\": 'bfm121M',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find project ds_mfmpre",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m run_occ \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m loss_v_C_runs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_list\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sfm/lib/python3.11/site-packages/wandb/apis/paginator.py:75\u001b[0m, in \u001b[0;36mPaginator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex:\n",
      "File \u001b[0;32m~/anaconda3/envs/sfm/lib/python3.11/site-packages/wandb/apis/paginator.py:62\u001b[0m, in \u001b[0;36mPaginator._load_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_variables()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQUERY, variable_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables\n\u001b[1;32m     61\u001b[0m )\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sfm/lib/python3.11/site-packages/wandb/apis/public/runs.py:133\u001b[0m, in \u001b[0;36mRuns.convert_objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m objs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find project \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run_response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    135\u001b[0m     run \u001b[38;5;241m=\u001b[39m Run(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient,\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         include_sweeps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_include_sweeps,\n\u001b[1;32m    142\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find project ds_mfmpre"
     ]
    }
   ],
   "source": [
    "# plot validation loss vs compute for all runs \n",
    "run_occ = {}\n",
    "loss_v_C_runs = []\n",
    "for run in runs:\n",
    "    if run.name not in run_list:\n",
    "        continue\n",
    "\n",
    "    loss_v_C_runs.append(run)\n",
    "\n",
    "    # if run.name not in run_occ:\n",
    "    #     run_occ[run.name] = 1\n",
    "    # else:\n",
    "    #     run_occ[run.name] = run_occ[run.name] + 1\n",
    "\n",
    "# sort runs by run_params\n",
    "loss_v_C_runs = sorted(loss_v_C_runs, key=lambda run: run_params[run.name])\n",
    "\n",
    "# Prepare lists for plotting  \n",
    "compute_values = []  \n",
    "loss_values = []  \n",
    "param_values = []  # List to store the parameter value for color mapping  \n",
    "\n",
    "\n",
    "loss_v_C = {}\n",
    "\n",
    "for run in loss_v_C_runs:  \n",
    "    N = run_params[run.name]  \n",
    "    D = 6000000  \n",
    "    tokens_per_iter = 1024 * 1536  \n",
    "    run_history = [row for row in run.scan_history()]  \n",
    "      \n",
    "    global_step = []  \n",
    "    losses = []\n",
    "    intervel = 5\n",
    "    idx = 0\n",
    "    for step in run_history[1:]:  \n",
    "        if 'train_inner/global_step' in step and 'train_inner/loss' in step and idx % intervel == 0:\n",
    "            s = step['train_inner/global_step']\n",
    "            if s is not None:\n",
    "                global_step.append(step['train_inner/global_step'])\n",
    "                losses.append(step['train_inner/loss_bpe'])\n",
    "        \n",
    "        idx = idx + 1\n",
    "    \n",
    "    \n",
    "    if run.name == \"bfm3B_data2_maskspan3_ddp2e5d16mask030drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2\":\n",
    "        compute = []\n",
    "        for step in global_step:\n",
    "            if step is None:\n",
    "                compute.append(0)\n",
    "            else:\n",
    "                compute.append(6 * N * step * 0.8 * tokens_per_iter)\n",
    "    elif run.name == \"bfm650m_data3_maskspan3_ddp4e5d16mask020drop1L1536B2k_bpev2pairv4_bert2_128A100_adam2\":\n",
    "        compute = []\n",
    "        for step in global_step:\n",
    "            if step is None:\n",
    "                compute.append(0)\n",
    "            else:\n",
    "                compute.append(6 * N * step * 2 * tokens_per_iter)\n",
    "    else:\n",
    "        compute = [6 * N * step * tokens_per_iter for step in global_step]\n",
    "\n",
    "    compute_values.append(compute)  \n",
    "    loss_values.append(losses)  \n",
    "    param_values.append([N] * len(compute))  # Use run parameter for color  \n",
    "\n",
    "# Create a scatter plot with colors based on run_params\n",
    "min_val = 5000000\n",
    "max_val = 5000000000\n",
    "norm = LogNorm(vmin=min_val, vmax=max_val)\n",
    "cmap = plt.get_cmap('plasma')  \n",
    "\n",
    "for idx in range(len(compute_values)):\n",
    "    color = cmap(norm(param_values[idx][0]))\n",
    "    plt.scatter(compute_values[idx], loss_values[idx], color=color, s=6)\n",
    "    plt.plot(compute_values[idx], loss_values[idx], '--', linewidth=1, color=color)\n",
    "\n",
    "sc = plt.scatter([], [], c=[], cmap='plasma', norm=norm)  \n",
    "\n",
    "# Add a color bar with a label  \n",
    "cbar = plt.colorbar(sc, norm=norm)  \n",
    "cbar.set_label('Parameter N')  \n",
    "cbar_ticks = [min_val, min_val*10, min_val*100, max_val]  \n",
    "cbar.set_ticks(cbar_ticks)  \n",
    "cbar.set_ticklabels(['5M', '50M', '500M', '5B'])  \n",
    "\n",
    "plt.xscale(\"log\")  \n",
    "plt.yscale(\"log\")  \n",
    "plt.xlabel(\"Compute (FLOPs)\")  \n",
    "plt.ylabel(\"Loss\")  \n",
    "plt.yticks(np.arange(2.0, 10.0, 0.5))  \n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))  \n",
    "plt.title(\"Loss vs compute for all training runs\")  \n",
    "\n",
    "\n",
    "# save plot with size 1280x960\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.savefig('./bfm_scalinglaw.png', dpi=300)\n",
    "\n",
    "# \n",
    "# {'train_inner/SamplePerSec': 618.5223999023438, 'train_inner/total_acc_sample': 204800, '_step': 1, 'train_inner/batch': 200, 'train_inner/total_samples': 12800, 'train_inner/epoch': 0, '_runtime': 737.9245097637177, 'train_inner/mlm_acc': 0.028053624629974364, 'train_inner/total_loss': 10.3392333984375, 'train_inner/bpe_acc': 0.00011197470128536224, 'train_inner/loss_type': 7.093716430664062, 'train_inner/loss_mlm': 3.6306381225585938, 'train_inner/loss': 10.339072408676147, 'train_inner/lr': 2.6533333333333333e-07, 'train_inner/loss_bpe': 9.870330810546875, '_timestamp': 1706400623.4756377, 'train_inner/type_acc': 0.0010210137069225312, 'train_inner/global_step': 200, 'train_inner/grad_scale': 1}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

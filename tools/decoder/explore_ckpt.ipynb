{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_home = '/hai1/ds_dataset/llama2/llama-2-7b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 262144838 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.hybrid_emb.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.0.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.1.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.10.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.11.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.12.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:17 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.13.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.14.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.15.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:17 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.16.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:17 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.17.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.18.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.19.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.2.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.20.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.21.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.22.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:17 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.23.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.24.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.25.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.26.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.27.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.28.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.29.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.3.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:17 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.30.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770343 Jul 29 09:17 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.31.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.4.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.5.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.6.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.7.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.8.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 404770331 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.layers.9.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users 262144829 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.lm_head.pt\n",
      "-rwxr-xr-x 1 FAREAST.shufxi FAREAST.domain users      8948 Jul 29 09:18 /hai1/ds_dataset/llama2/llama-2-7b/model.norm.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls -l $ckpt_home/model.*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_attn.q_proj.weight',\n",
      " 'self_attn.k_proj.weight',\n",
      " 'self_attn.v_proj.weight',\n",
      " 'self_attn.o_proj.weight',\n",
      " 'mlp.gate_proj.weight',\n",
      " 'mlp.down_proj.weight',\n",
      " 'mlp.up_proj.weight',\n",
      " 'input_layernorm.weight',\n",
      " 'post_attention_layernorm.weight',\n",
      " 'self_attn.rotary_emb.inv_freq']\n"
     ]
    }
   ],
   "source": [
    "ckpt_data = torch.load(f'{ckpt_home}/model.layers.0.pt')\n",
    "\n",
    "pp.pprint(list(ckpt_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lm_head.weight']\n"
     ]
    }
   ],
   "source": [
    "ckpt_data = torch.load(f'{ckpt_home}/model.lm_head.pt')\n",
    "\n",
    "pp.pprint(list(ckpt_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "text_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    ckpt_home, use_fast=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True),\n",
       " 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True),\n",
       " 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True),\n",
       " 'pad_token': '[PAD]',\n",
       " 'additional_special_tokens': ['[M]']}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer.special_tokens_map_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer.add_special_tokens({\"additional_special_tokens\": ['[M]']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32001"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer.convert_tokens_to_ids('[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁<', 'start', '-', 'of', '-', 'm', 'ol', '>']\n",
      "0 给\n",
      "1 弘\n",
      "2 收\n",
      "3 왕\n",
      "4 黃\n",
      "5 还\n",
      "6 边\n",
      "7 べ\n",
      "8 げ\n",
      "9 ὀ\n",
      "10 백\n",
      "11 泰\n",
      "12 역\n",
      "13 联\n",
      "14 怪\n",
      "15 奇\n",
      "16 ɯ\n",
      "17 番\n",
      "18 止\n",
      "19 합\n"
     ]
    }
   ],
   "source": [
    "spm = text_tokenizer.sp_model\n",
    "\n",
    "print(spm.encode('<start-of-mol>', out_type=str))\n",
    "\n",
    "for idx in range(20):\n",
    "    print(idx, spm.id_to_piece(32000-1-idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('/home/shufxi/mixgpt/mixgpt_new/ckpt/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biogpt.embed_tokens.weight',\n",
      " 'biogpt.embed_positions.weight',\n",
      " 'biogpt.layers.0.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.0.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.0.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.0.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.0.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.0.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.0.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.0.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.0.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.0.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.0.fc1.weight',\n",
      " 'biogpt.layers.0.fc1.bias',\n",
      " 'biogpt.layers.0.fc2.weight',\n",
      " 'biogpt.layers.0.fc2.bias',\n",
      " 'biogpt.layers.0.final_layer_norm.weight',\n",
      " 'biogpt.layers.0.final_layer_norm.bias',\n",
      " 'biogpt.layers.1.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.1.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.1.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.1.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.1.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.1.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.1.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.1.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.1.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.1.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.1.fc1.weight',\n",
      " 'biogpt.layers.1.fc1.bias',\n",
      " 'biogpt.layers.1.fc2.weight',\n",
      " 'biogpt.layers.1.fc2.bias',\n",
      " 'biogpt.layers.1.final_layer_norm.weight',\n",
      " 'biogpt.layers.1.final_layer_norm.bias',\n",
      " 'biogpt.layers.2.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.2.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.2.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.2.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.2.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.2.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.2.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.2.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.2.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.2.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.2.fc1.weight',\n",
      " 'biogpt.layers.2.fc1.bias',\n",
      " 'biogpt.layers.2.fc2.weight',\n",
      " 'biogpt.layers.2.fc2.bias',\n",
      " 'biogpt.layers.2.final_layer_norm.weight',\n",
      " 'biogpt.layers.2.final_layer_norm.bias',\n",
      " 'biogpt.layers.3.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.3.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.3.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.3.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.3.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.3.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.3.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.3.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.3.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.3.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.3.fc1.weight',\n",
      " 'biogpt.layers.3.fc1.bias',\n",
      " 'biogpt.layers.3.fc2.weight',\n",
      " 'biogpt.layers.3.fc2.bias',\n",
      " 'biogpt.layers.3.final_layer_norm.weight',\n",
      " 'biogpt.layers.3.final_layer_norm.bias',\n",
      " 'biogpt.layers.4.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.4.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.4.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.4.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.4.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.4.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.4.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.4.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.4.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.4.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.4.fc1.weight',\n",
      " 'biogpt.layers.4.fc1.bias',\n",
      " 'biogpt.layers.4.fc2.weight',\n",
      " 'biogpt.layers.4.fc2.bias',\n",
      " 'biogpt.layers.4.final_layer_norm.weight',\n",
      " 'biogpt.layers.4.final_layer_norm.bias',\n",
      " 'biogpt.layers.5.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.5.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.5.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.5.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.5.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.5.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.5.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.5.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.5.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.5.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.5.fc1.weight',\n",
      " 'biogpt.layers.5.fc1.bias',\n",
      " 'biogpt.layers.5.fc2.weight',\n",
      " 'biogpt.layers.5.fc2.bias',\n",
      " 'biogpt.layers.5.final_layer_norm.weight',\n",
      " 'biogpt.layers.5.final_layer_norm.bias',\n",
      " 'biogpt.layers.6.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.6.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.6.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.6.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.6.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.6.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.6.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.6.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.6.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.6.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.6.fc1.weight',\n",
      " 'biogpt.layers.6.fc1.bias',\n",
      " 'biogpt.layers.6.fc2.weight',\n",
      " 'biogpt.layers.6.fc2.bias',\n",
      " 'biogpt.layers.6.final_layer_norm.weight',\n",
      " 'biogpt.layers.6.final_layer_norm.bias',\n",
      " 'biogpt.layers.7.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.7.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.7.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.7.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.7.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.7.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.7.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.7.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.7.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.7.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.7.fc1.weight',\n",
      " 'biogpt.layers.7.fc1.bias',\n",
      " 'biogpt.layers.7.fc2.weight',\n",
      " 'biogpt.layers.7.fc2.bias',\n",
      " 'biogpt.layers.7.final_layer_norm.weight',\n",
      " 'biogpt.layers.7.final_layer_norm.bias',\n",
      " 'biogpt.layers.8.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.8.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.8.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.8.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.8.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.8.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.8.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.8.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.8.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.8.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.8.fc1.weight',\n",
      " 'biogpt.layers.8.fc1.bias',\n",
      " 'biogpt.layers.8.fc2.weight',\n",
      " 'biogpt.layers.8.fc2.bias',\n",
      " 'biogpt.layers.8.final_layer_norm.weight',\n",
      " 'biogpt.layers.8.final_layer_norm.bias',\n",
      " 'biogpt.layers.9.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.9.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.9.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.9.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.9.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.9.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.9.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.9.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.9.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.9.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.9.fc1.weight',\n",
      " 'biogpt.layers.9.fc1.bias',\n",
      " 'biogpt.layers.9.fc2.weight',\n",
      " 'biogpt.layers.9.fc2.bias',\n",
      " 'biogpt.layers.9.final_layer_norm.weight',\n",
      " 'biogpt.layers.9.final_layer_norm.bias',\n",
      " 'biogpt.layers.10.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.10.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.10.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.10.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.10.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.10.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.10.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.10.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.10.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.10.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.10.fc1.weight',\n",
      " 'biogpt.layers.10.fc1.bias',\n",
      " 'biogpt.layers.10.fc2.weight',\n",
      " 'biogpt.layers.10.fc2.bias',\n",
      " 'biogpt.layers.10.final_layer_norm.weight',\n",
      " 'biogpt.layers.10.final_layer_norm.bias',\n",
      " 'biogpt.layers.11.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.11.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.11.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.11.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.11.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.11.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.11.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.11.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.11.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.11.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.11.fc1.weight',\n",
      " 'biogpt.layers.11.fc1.bias',\n",
      " 'biogpt.layers.11.fc2.weight',\n",
      " 'biogpt.layers.11.fc2.bias',\n",
      " 'biogpt.layers.11.final_layer_norm.weight',\n",
      " 'biogpt.layers.11.final_layer_norm.bias',\n",
      " 'biogpt.layers.12.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.12.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.12.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.12.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.12.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.12.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.12.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.12.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.12.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.12.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.12.fc1.weight',\n",
      " 'biogpt.layers.12.fc1.bias',\n",
      " 'biogpt.layers.12.fc2.weight',\n",
      " 'biogpt.layers.12.fc2.bias',\n",
      " 'biogpt.layers.12.final_layer_norm.weight',\n",
      " 'biogpt.layers.12.final_layer_norm.bias',\n",
      " 'biogpt.layers.13.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.13.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.13.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.13.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.13.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.13.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.13.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.13.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.13.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.13.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.13.fc1.weight',\n",
      " 'biogpt.layers.13.fc1.bias',\n",
      " 'biogpt.layers.13.fc2.weight',\n",
      " 'biogpt.layers.13.fc2.bias',\n",
      " 'biogpt.layers.13.final_layer_norm.weight',\n",
      " 'biogpt.layers.13.final_layer_norm.bias',\n",
      " 'biogpt.layers.14.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.14.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.14.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.14.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.14.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.14.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.14.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.14.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.14.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.14.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.14.fc1.weight',\n",
      " 'biogpt.layers.14.fc1.bias',\n",
      " 'biogpt.layers.14.fc2.weight',\n",
      " 'biogpt.layers.14.fc2.bias',\n",
      " 'biogpt.layers.14.final_layer_norm.weight',\n",
      " 'biogpt.layers.14.final_layer_norm.bias',\n",
      " 'biogpt.layers.15.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.15.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.15.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.15.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.15.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.15.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.15.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.15.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.15.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.15.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.15.fc1.weight',\n",
      " 'biogpt.layers.15.fc1.bias',\n",
      " 'biogpt.layers.15.fc2.weight',\n",
      " 'biogpt.layers.15.fc2.bias',\n",
      " 'biogpt.layers.15.final_layer_norm.weight',\n",
      " 'biogpt.layers.15.final_layer_norm.bias',\n",
      " 'biogpt.layers.16.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.16.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.16.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.16.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.16.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.16.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.16.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.16.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.16.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.16.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.16.fc1.weight',\n",
      " 'biogpt.layers.16.fc1.bias',\n",
      " 'biogpt.layers.16.fc2.weight',\n",
      " 'biogpt.layers.16.fc2.bias',\n",
      " 'biogpt.layers.16.final_layer_norm.weight',\n",
      " 'biogpt.layers.16.final_layer_norm.bias',\n",
      " 'biogpt.layers.17.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.17.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.17.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.17.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.17.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.17.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.17.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.17.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.17.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.17.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.17.fc1.weight',\n",
      " 'biogpt.layers.17.fc1.bias',\n",
      " 'biogpt.layers.17.fc2.weight',\n",
      " 'biogpt.layers.17.fc2.bias',\n",
      " 'biogpt.layers.17.final_layer_norm.weight',\n",
      " 'biogpt.layers.17.final_layer_norm.bias',\n",
      " 'biogpt.layers.18.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.18.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.18.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.18.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.18.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.18.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.18.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.18.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.18.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.18.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.18.fc1.weight',\n",
      " 'biogpt.layers.18.fc1.bias',\n",
      " 'biogpt.layers.18.fc2.weight',\n",
      " 'biogpt.layers.18.fc2.bias',\n",
      " 'biogpt.layers.18.final_layer_norm.weight',\n",
      " 'biogpt.layers.18.final_layer_norm.bias',\n",
      " 'biogpt.layers.19.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.19.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.19.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.19.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.19.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.19.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.19.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.19.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.19.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.19.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.19.fc1.weight',\n",
      " 'biogpt.layers.19.fc1.bias',\n",
      " 'biogpt.layers.19.fc2.weight',\n",
      " 'biogpt.layers.19.fc2.bias',\n",
      " 'biogpt.layers.19.final_layer_norm.weight',\n",
      " 'biogpt.layers.19.final_layer_norm.bias',\n",
      " 'biogpt.layers.20.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.20.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.20.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.20.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.20.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.20.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.20.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.20.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.20.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.20.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.20.fc1.weight',\n",
      " 'biogpt.layers.20.fc1.bias',\n",
      " 'biogpt.layers.20.fc2.weight',\n",
      " 'biogpt.layers.20.fc2.bias',\n",
      " 'biogpt.layers.20.final_layer_norm.weight',\n",
      " 'biogpt.layers.20.final_layer_norm.bias',\n",
      " 'biogpt.layers.21.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.21.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.21.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.21.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.21.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.21.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.21.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.21.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.21.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.21.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.21.fc1.weight',\n",
      " 'biogpt.layers.21.fc1.bias',\n",
      " 'biogpt.layers.21.fc2.weight',\n",
      " 'biogpt.layers.21.fc2.bias',\n",
      " 'biogpt.layers.21.final_layer_norm.weight',\n",
      " 'biogpt.layers.21.final_layer_norm.bias',\n",
      " 'biogpt.layers.22.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.22.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.22.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.22.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.22.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.22.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.22.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.22.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.22.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.22.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.22.fc1.weight',\n",
      " 'biogpt.layers.22.fc1.bias',\n",
      " 'biogpt.layers.22.fc2.weight',\n",
      " 'biogpt.layers.22.fc2.bias',\n",
      " 'biogpt.layers.22.final_layer_norm.weight',\n",
      " 'biogpt.layers.22.final_layer_norm.bias',\n",
      " 'biogpt.layers.23.self_attn.k_proj.weight',\n",
      " 'biogpt.layers.23.self_attn.k_proj.bias',\n",
      " 'biogpt.layers.23.self_attn.v_proj.weight',\n",
      " 'biogpt.layers.23.self_attn.v_proj.bias',\n",
      " 'biogpt.layers.23.self_attn.q_proj.weight',\n",
      " 'biogpt.layers.23.self_attn.q_proj.bias',\n",
      " 'biogpt.layers.23.self_attn.out_proj.weight',\n",
      " 'biogpt.layers.23.self_attn.out_proj.bias',\n",
      " 'biogpt.layers.23.self_attn_layer_norm.weight',\n",
      " 'biogpt.layers.23.self_attn_layer_norm.bias',\n",
      " 'biogpt.layers.23.fc1.weight',\n",
      " 'biogpt.layers.23.fc1.bias',\n",
      " 'biogpt.layers.23.fc2.weight',\n",
      " 'biogpt.layers.23.fc2.bias',\n",
      " 'biogpt.layers.23.final_layer_norm.weight',\n",
      " 'biogpt.layers.23.final_layer_norm.bias',\n",
      " 'biogpt.layer_norm.weight',\n",
      " 'biogpt.layer_norm.bias',\n",
      " 'output_projection.weight']\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(ckpt.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm.data.dec_data.SFMDecTokenizer import SFMDecTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BioGptTokenizer'. \n",
      "The class this function is called from is 'SFMDecTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "entity_tokenizer = SFMDecTokenizer.from_pretrained(\"/home/shufxi/mixgpt/mixgpt_new/ckpt\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M]CN(N=O)C(N)=O[/M]\n",
      "[4, 40, 47, 41, 47, 45, 44, 42, 40, 41, 47, 42, 45, 44, 9]\n",
      "['[M]</w>', '<m>C</w>', '<m>N</w>', '<m>(</w>', '<m>N</w>', '<m>=</w>', '<m>O</w>', '<m>)</w>', '<m>C</w>', '<m>(</w>', '<m>N</w>', '<m>)</w>', '<m>=</w>', '<m>O</w>', '[/M]</w>']\n",
      "[M]CN(N=O)C(N)=O[/M]\n"
     ]
    }
   ],
   "source": [
    "smiels = \"<start-of-mol> <m>C <m>N <m>( <m>N <m>= <m>O <m>) <m>C <m>( <m>N <m>) <m>= <m>O <end-of-mol>\".replace(\"<m>\", \" \").replace(\" \", \"\")\n",
    "smiels = smiels.replace('<start-of-mol>', '[M]').replace('<end-of-mol>', '[/M]')\n",
    "print(smiels)\n",
    "ids = entity_tokenizer(smiels, add_special_tokens=False)['input_ids']\n",
    "\n",
    "print(ids)\n",
    "print(entity_tokenizer.convert_ids_to_tokens(ids))\n",
    "\n",
    "\n",
    "print(entity_tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s><unk><m>C <m>N <m>( <m>N <m>= <m>O <m>) <m>C <m>( <m>N <m>) <m>= <m>O <unk>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_tokenizer.decode([ 2,  3, 40, 47, 41, 47, 45, 44, 42, 40, 41, 47, 42, 45, 44,  3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[M]</w>'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_tokenizer.convert_ids_to_tokens([4])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 3]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_tokenizer.encode('<start-of-mol>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
